Introduction to Geostatistics
AndraÃÅs BaÃÅrdossy
Institute of Hydraulic Engineering
University of Stuttgart

1

Contents
1

2

3

Introduction

6

1.1

Variability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

6

1.2

Stochastic methods . . . . . . . . . . . . . . . . . . . . . . . . .

6

1.3

Geostatistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

8

1.4

Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

9

Statistical hypotheses

11

2.1

Basic concepts . . . . . . . . . . . . . . . . . . . . . . . . . . .

11

2.2

Regionalized variables . . . . . . . . . . . . . . . . . . . . . . .

13

2.3

Second order stationarity . . . . . . . . . . . . . . . . . . . . . .

14

2.4

Intrinsic hypothesis . . . . . . . . . . . . . . . . . . . . . . . . .

15

2.5

Comparison of the two hypotheses . . . . . . . . . . . . . . . . .

16

2.6

Selection of the regionalized variable . . . . . . . . . . . . . . . .

17

The variogram

19

3.1

The experimental variogram . . . . . . . . . . . . . . . . . . . .

22

3.1.1

Practice of experimental variogram calculation . . . . . .

24

The theoretical variogram . . . . . . . . . . . . . . . . . . . . . .

28

3.2.1

Variogram models with a sill . . . . . . . . . . . . . . . .

29

3.2.2

Variogram models without sill . . . . . . . . . . . . . . .

32

3.3

Variogram fitting . . . . . . . . . . . . . . . . . . . . . . . . . .

34

3.4

Isotropy ‚Äî anisotropy . . . . . . . . . . . . . . . . . . . . . . .

37

3.4.1

Geometric anisotropy . . . . . . . . . . . . . . . . . . . .

38

3.4.2

Zonal anisotropy . . . . . . . . . . . . . . . . . . . . . .

39

3.2

2

4

Ordinary Kriging

40

4.1

Point kriging . . . . . . . . . . . . . . . . . . . . . . . . . . . .

40

4.2

Block kriging . . . . . . . . . . . . . . . . . . . . . . . . . . . .

44

4.3

Properties of ordinary kriging . . . . . . . . . . . . . . . . . . . .

46

4.3.1

Kriging as an interpolator . . . . . . . . . . . . . . . . .

46

4.3.2

Kriging and the variogram . . . . . . . . . . . . . . . . .

49

Practice of kriging . . . . . . . . . . . . . . . . . . . . . . . . . .

52

4.4.1

Selection of the neighbourhood . . . . . . . . . . . . . .

52

4.4.2

Kriging with a ‚Äúfalse‚Äù variogram . . . . . . . . . . . . . .

52

4.5

Cross validation . . . . . . . . . . . . . . . . . . . . . . . . . . .

53

4.6

Kriging with uncertain data . . . . . . . . . . . . . . . . . . . . .

54

4.7

Simple Kriging . . . . . . . . . . . . . . . . . . . . . . . . . . .

59

4.4

5

6

7

Non stationary methods

60

5.1

Universal kriging . . . . . . . . . . . . . . . . . . . . . . . . . .

61

5.2

Intrinsic random functions of order k . . . . . . . . . . . . . . . .

64

5.3

External-Drift-Kriging . . . . . . . . . . . . . . . . . . . . . . .

71

Indicator Kriging

73

6.1

Indicator Variables . . . . . . . . . . . . . . . . . . . . . . . . .

73

6.2

Indicator Variograms . . . . . . . . . . . . . . . . . . . . . . . .

74

6.3

Indicator Kriging . . . . . . . . . . . . . . . . . . . . . . . . . .

74

6.4

Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

76

6.4.1

Interpolation of a categorical variable . . . . . . . . . . .

76

6.4.2

Detection limit problem . . . . . . . . . . . . . . . . . .

76

Kriging with arbitrary additional information

79

7.1

Markov-Bayes-Kriging . . . . . . . . . . . . . . . . . . . . . . .

79

7.2

Simple Updating (SU) . . . . . . . . . . . . . . . . . . . . . . .

81

3

8

9

Time dependent variables

92

8.1

Space ‚Äî time intrinsic variables . . . . . . . . . . . . . . . . . .

93

8.2

Spatially intrinsic variables with time independent variograms . .

94

8.3

Spatially intrinsic variables with time dependent variograms . . .

95

8.4

Time series interpreted as different realisations . . . . . . . . . .

95

Simulation

98

9.1

Basic definitions . . . . . . . . . . . . . . . . . . . . . . . . . . .

99

9.2

Monte Carlo Simulations . . . . . . . . . . . . . . . . . . . . . .

99

9.3

Turning Band Simulation . . . . . . . . . . . . . . . . . . . . . . 100
9.3.1

Unconditional simulation . . . . . . . . . . . . . . . . . . 101

9.3.2

Conditional simulation . . . . . . . . . . . . . . . . . . . 104

9.4

Sequential Simulation . . . . . . . . . . . . . . . . . . . . . . . . 105

9.5

Simulation using Markov Chains . . . . . . . . . . . . . . . . . . 105

9.6

9.5.1

The Hastings Algorithm . . . . . . . . . . . . . . . . . . 105

9.5.2

Simulated annealing . . . . . . . . . . . . . . . . . . . . 106

Indicator Simulation . . . . . . . . . . . . . . . . . . . . . . . . 110
9.6.1

9.7

Truncated-Gaussian Simulation . . . . . . . . . . . . . . 110

Application of simulations . . . . . . . . . . . . . . . . . . . . . 110
9.7.1

Examples . . . . . . . . . . . . . . . . . . . . . . . . . . 111

10 Exercises

112

10.1 The Variogram . . . . . . . . . . . . . . . . . . . . . . . . . . . 112
10.1.1 Question: 1 . . . . . . . . . . . . . . . . . . . . . . . . . 112
10.1.2 Solution: 1 . . . . . . . . . . . . . . . . . . . . . . . . . 112
10.1.3 Question: 2 . . . . . . . . . . . . . . . . . . . . . . . . . 114
10.1.4 Solution: 2 . . . . . . . . . . . . . . . . . . . . . . . . . 115
10.1.5 Question: 3 . . . . . . . . . . . . . . . . . . . . . . . . . 117
10.1.6 Solution: 3 . . . . . . . . . . . . . . . . . . . . . . . . . 118
10.1.7 Question: 4 . . . . . . . . . . . . . . . . . . . . . . . . . 119
10.1.8 Solution: 4 . . . . . . . . . . . . . . . . . . . . . . . . . 120
4

10.2 Ordinary Kriging . . . . . . . . . . . . . . . . . . . . . . . . . . 121
10.2.1 Question: 1 . . . . . . . . . . . . . . . . . . . . . . . . . 121
10.2.2 Solution: 1 . . . . . . . . . . . . . . . . . . . . . . . . . 122
10.2.3 Question: 2 . . . . . . . . . . . . . . . . . . . . . . . . . 124
10.2.4 Solution: 2 . . . . . . . . . . . . . . . . . . . . . . . . . 124
10.2.5 Question: 3 . . . . . . . . . . . . . . . . . . . . . . . . . 127
10.2.6 Solution: 3 . . . . . . . . . . . . . . . . . . . . . . . . . 128
10.3 Short Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . 130
10.3.1 Question: 1 . . . . . . . . . . . . . . . . . . . . . . . . . 130
10.3.2 Solution: 1 . . . . . . . . . . . . . . . . . . . . . . . . . 131
10.3.3 Question: 2 . . . . . . . . . . . . . . . . . . . . . . . . . 131
10.3.4 Solution: 2 . . . . . . . . . . . . . . . . . . . . . . . . . 132
11 References

134

5

Chapter 1
Introduction
1.1

Variability

Most of the natural phenomena we study are variable both in space and time.
Considering a topographic surface or a groundwater contamination one can observe high variability within small distances. The variability is a result of natural
processes, thus deterministic. As most of these processes are sensitive and the
conditions under which the they took place are not fully known, it is not possible
to describe them based on physical and chemical laws completely.
The practical consequences of variability are:
‚Ä¢ field and laboratory measurements are necessary
‚Ä¢ upscaling is non trivial
‚Ä¢ there is always a limited degree of explanation one can achieve

1.2

Stochastic methods

It is not uncommon to use probabilistic and statistical methods for describing
partly known (or sampled) natural parameters. Philosophically the appropriate6

ness of this approach can be argued. As the realization under study already exists
at the moment of the investigation, there is no randomness present in the sense of
the traditional approach.
On the other side, this kind of existence does not contradict the application
of probabilistic and statistical methods. For example, one faces the same kind
of uncertainty before tossing a coin and after it if the coin is covered immediately, before one can see it. The more disturbing and restricting problem is the
uniqueness of the realization. A coin can be tossed several times, but a natural
phenomenon cannot be repeated. This means that no frequencies are available,
and thus probabilities cannot be assessed this way.
Measurement values of a certain parameter, obtained from different locations
are often treated as different outcomes of the same random variable. Means and
variances, cumulative distributions etc. are calculated this way. However, the
hypothesis of independent trials is not always applicable. Consider the following
simple example.

7

EXAMPLE 1.1 :

No.of samples

Mean

Variance

12

279.5

4554

21

283.9

7072

46

281.6

8646

Table 1.1: Means and variances calculated from different samples
Elevation of 46 meteorological stations was considered. As a first step mean
and variance corresponding to the central 12 stations were calculated. Then a bit
bigger neighbourhood was considered; finally all stations were included. Table
1.1 shows the means and variances. Note that the mean does not change, while
the variance increases with the sample size (proportional to the area covered by
these stations). If the parameter is modeled as the realization of a random variable,
then the usual assumption of independence would contradict the increase of the
variance.

1.3

Geostatistics

Time series analysis is one of the first fields where variability has been considered
and described with stochastic methods. These methods were extended and further
developed to analyse spatial variability. These spatial methods form the discipline
called geostatistics.
The word geostatistics is formed from the two parts geo and statistics similarly to geophysics or geochemistry. It is used with two different meanings:
1. as a collection of all statistical and probabilistic methods applied in geo
sciences,
8

2. as an other name for the theory of regionalized variables.
The theory of regionalized variables, which is the topic of the next pages dates
back to the early fifties when in South-Africa D. Krige and his colleagues started
to apply statistical techniques to ore reserve estimation. In the sixties the french
matematician G. Matheron gave theoretical foundations to the above methods.
Geostatistics was first used by the mining industry, as high costs of drillings made
the analysis of the data extremely important. Books and publications on geostatistics are mostly oriented to mining problems. As the computers got cheaper and
cheaper the computationally expensive methods could also be used in other topics.
Applications of geostatistics can be found in very different disciplines ranging
from the classical fields mining and geology to soil science, hydrology, meteorology, environmental sciences, agriculture, even structural engineering.
The following text does not contain a complete theory of geostatistical methods illustrated with applications. It is planned to be a practical introduction. Theoretical results and long derivations are not included, results are mostly presented
without detailed proofs. However, the ideas behind these results are always presented.

1.4

Notation

Throughout the following text u will always denote a point in the d dimensional
space u = x if d = 1, u = (x, y) if d = 2 and u = (x, y, w) if d = 3; if time also plays a
role it will be denoted by t. Measurement points are indexed, ui = (xi , . . .). Spaces
of different dimensions d = 1, . . . , 3 will be considered, and the formulation is
given in a general form.
For simplicity the notation

R

f (u) du will be used for single, double, and triple

9

integrals, too:
Ô£±
R
Ô£¥
Ô£¥
f (x)dx
Ô£¥
Ô£¥
Ô£¥
Z
Ô£≤
RR
f (u)du =
f (x, y)dx dy
Ô£¥
Ô£¥
Ô£¥
Ô£¥
Ô£¥
Ô£≥ R R R f (x, y, w)dx dy dw

if d = 1
if d = 2

(1.1)

if d = 3

Some double integrals can also appear in the text, they are meant to be double
integrals in the above (1.1) sense.

10

Chapter 2
Statistical hypotheses
2.1

Basic concepts

Loosely speaking a random variable is a function Z which might take different values (outcomes) with given probabilities. If the outcomes form a finite (or coutably
infinite) set then one speaks of a discrete random variable.
Random variables are characterized by their distribution function:
FZ (z) = P[Z ‚â§ z]

(2.1)

Distribution functions are non-decreasing with values in [0, 1]. The probability of
Z being in the interval [a, b] can be calculated using the distribution function:
P[a < Z ‚â§ b] = F(b) ‚àí F(a)

(2.2)

For many non-discrete random variables the distribution function F is connected to the density function f through:
Zz

FZ (z) =

fZ (t) dt

(2.3)

‚àí‚àû

The expected value of a random variable is its ‚Äômean value over infinetely
11

many realizations‚Äô. It is:
Z+‚àû

E[Z] =

t dFZ (t)

(2.4)

‚àí‚àû

For random variables with density function this can be written as:
Z+‚àû

E[Z] =

t fZ (t) dt

(2.5)

‚àí‚àû

Moments of a random variable are defined as:
Z+‚àû

m

t m dFZ (t)

E[Z ] =

(2.6)

‚àí‚àû

The central moments are:
m

E[(Z ‚àí E[Z]) ] =

Z+‚àû

(t ‚àí E[Z])m dFZ (t)

(2.7)

‚àí‚àû

The second central moment is called variance:
Var[Z] = œÉ2 = E[(Z 2 ‚àí E[Z])2 ]

(2.8)

The expected value has a linear behavior:
E[Z1 + Z2 ] = E[Z1 ] + E[Z2 ]

(2.9)

E[aZ] = aE[Z]

(2.10)

and

This is not true for the higher moments and in general for non-linear functions g:
E[g(Z)] 6= g(E[Z])

(2.11)

The joint behavior of more random variables Z1 , . . . , Zn can be described by
their joint distribution function:
FZ1 ,...,Zn (z1 , . . . , zn ) = P[Z1 ‚â§ z1 and . . . and Zn ‚â§ zn ]
12

(2.12)

2.2

Regionalized variables

In the theory of regionalized variables the concept of random functions plays a
central role. A random function is a set of random variables corresponding to the
points of the domain D under study. This means that for each point u in D there is
a corresponding random variable Z(u).
A regionalized variable is the realization of a random function. This means
that for each point u in the d dimensional space the value of the parameter we
are interested in, z(u) is one realization of the random function Z(u). This interpretation of the natural parameters acknowledges the fact that it is not possible
to describe them completely using deterministic methods only. In most cases it
is impossible to check the assumption that the parameter is the realization of a
random function as we have to deal with a single realization.
One could describe a random function by its multidimensional distribution
functions. This means that for each set of points u1 , . . . , un in the domain D, a
cumulative distribution function Fu1 ,...,un is assigned. Using these functions for
each set of possible values w1 , . . . , wn one could find the probability P :
P(Z(u1 ) < w1 , . . . , Z(un ) < wn ) = Fu1 ,...,un (w1 , . . . , wn )

(2.13)

This would mean that conditional probabilities could be used for the estimation of local or global averages etc. Unfortunately there are infinitely many finite
subsets in the domain D, and as for each point in D usually only one value (the
realization) is available the assessment of the distribution functions based on the
experimental data seems to be illusory. Even in the case of repeatedly measured
parameters (for example groundwater quality) there are not enough measurements
to assess the above distribution functions.
A general hypothesis which reduces the complexity of the problem is the so
called strong stationarity . Formally it is:
The random function Z(u) is stationary if for each set of points u1 , . . . , un in the
domain D, and for each set of possible values w1 , . . . , wn , and for each vector h:
P(Z(u1 ) < w1 , . . . , Z(un ) < wn ) = P(Z(u1 + h) < w1 , . . . , Z(un + h) < wn ) (2.14)
13

This equation means that the distribution of the random function depends on the
configuration of the points and not on their locations. In other words this can be
formulated that ‚Äúnature‚Äù repeats itself similarly for the same configuration.
The assumption of strong stationarity is useful, but still a bit too complex to be
appropriate. To deal with the problem effectively some even simpler assumptions
have to be made. The two basic and very similar assumptions are the following:

2.3

Second order stationarity

Stationarity is a concept often used in time series analysis. Here the second order
stationarity hypothesis is formulated for multidimensional spaces.
The assumption of second order stationarity consists of two conditions:
‚Ä¢ The expected value of the random function Z(u) is constant all over the
domain D.
‚Ä¢ The covariance of two random variables corresponding to two locations depends only on the vector h separating these two points.
These conditions can be formulated as:
E[Z(u)] = m

(2.15)

E[(Z(u + h) ‚àí m)(Z(u) ‚àí m)] = C(h)

(2.16)

for all u ‚àà D
for any u, u + h ‚àà D, where C(h) depends only on the vector h and not on the
locations u and u + h. The function C(h) is called covariance function. In this
case one has for h = 0 :
C(0) = E[(Z(u) ‚àí m)(Z(u) ‚àí m)] = Var[Z(u)]

(2.17)

Equation (2.17) shows that the random variables corresponding to different points
in the domain do not only have the same expectation, but they also have to have
the same finite variance. This second condition is not always met, but weaker
assumptions can be formulated.
14

2.4

Intrinsic hypothesis

The assumption slighly weaker than the second order stationarity is the so called
intrinsic hypothesis. The first condition is the same as in the case of second order
stationarity, only the second is different:
‚Ä¢ The expected value of the random function Z(u) is constant all over the
domain D.
‚Ä¢ The variance of the increment corresponding to two different locations depends only on the vector separating them.
These conditions can be formulated as:
E[Z(u)] = m

(2.18)

1
1
Var[Z(u + h) ‚àí Z(u)] = E[(Z(u + h) ‚àí Z(u))2 ] = Œ≥(h)
2
2

(2.19)

for all u ‚àà D

where Œ≥(h) depends only on the vector h and not on the locations u and u + h. The
function Œ≥(h) is called semivariogram . The semivariogram is often called simply
variogram , for convenience this sloppy convention will be used throughout this
text. One can see that equation (2.19) is very similar to (2.16), but the implicit
assumption of the finite variance is not included. It can be demonstrated that the
second order stationarity implies the intrinsic hypothesis, but the converse is not
true. In the case of second order stationarity one has:
E[(Z(u + h) ‚àí Z(u))2 ] = E[((Z(u + h) ‚àí m) ‚àí (Z(u) ‚àí m))2 ] =
= Var[Z(u)] +Var[Z(u + h)] ‚àí 2E[(Z(u + h) ‚àí m)(Z(u) ‚àí m)] = 2C(0) ‚àí 2C(h)
(2.20)
So the relation:
Œ≥(h) = C(0) ‚àíC(h)

(2.21)

Figure 2.1 shows this relationship between the covariance function and the variogram.
15

Variance
6
(

!

SS
S
S
SS
\
\
\
\
e
e

Œ≥(h)

"

#
,

%
e
e%
%
e
%e
%
%










@
@
@
l
c
Z
bH
aP
`h

C(h)
-

Distance

Figure 2.1: The covariance function C(h) and the variogram Œ≥(h)
The intrinsic hypothesis was first considered by pioneers of geostatistics in
South Africa. The assumption of finite variances in gold deposits did not seem to
be suitable, this led to the introduction of this hypothesis.

2.5

Comparison of the two hypotheses

The difference between the intrinsic hypothesis and the second order stationarity
is not only the fact that the first is more general than the second. The covariance
function (2.16) is defined using the value of the expectation m, while the variogram (2.19) does not depend on this value. This is an advantage because slight
trends do not influence the variogram severely, in contrast to the covariance function where through the improper estimation of the mean these effects are more
severe.

16

2.6

Selection of the regionalized variable

The regionalized variable under study has to fulfill certain conditions to apply
geostatistical methods. These conditions are:
1. Data homogeneity: The data should reflect one parameter, measured by the
same measurement method, and the measurements should be made on the
same volume (support).
2. Additivity : The parameter should have the property that 1n ‚àëni=1 Z(ui ) has
the same meaning as Z(u).
To understand the meaning of the additivity condition consider the following example:
EXAMPLE 2.1 :
Suppose that Z(u) represents the thickness of a layer measured in m. If the
average thickness over a certain area is needed, then the arithmetic mean of a
regular sampling is a good estimator for this. If instead Z 0 (u) is the cube of the
thickness then the arithmetic mean of the individual Z 0 (ui ) values is not the cube
of the mean thickness. To see this explicitly suppose two samples are available:
Z(u1 ) = 1 and Z(u2 ) = 2. So Z 0 (u1 ) = 1 and Z 0 (u2 ) = 8. Then for the mean one
has
0.5Z(u1 ) + 0.5Z(u2 ) = 1.5
0.5Z 0 (u1 ) + 0.5Z 0 (u2 ) = 4.5
but using the definition of Z 0 (u) one has:
(0.5Z(u1 ) + 0.5Z(u2 ))3 = 3.375
This means that Z 0 (u) is not additive.
Some natural parameters are clearly non additive, like hydraulic conductivity
etc. In the case of non additive parameters it is possible to use transformations
17

which transform them to additive ones. Data homogeneity problems (like different
measurement types) can sometimes be overcome, some cases are discussed later.

18

Chapter 3
The variogram
As the variogram is defined the variance of an increment certainly has to fulfil
several conditions. The precise conditions of a variogram will be discussed in the
section describing the theoretical variograms. Naturally there are also properties
of the variogram which we know or suppose without any precise mathematical
description.
‚Ä¢ From the definition we have Œ≥(0) = 0 .
‚Ä¢ From the definition Œ≥(h) ‚â• 0 for all h vectors
‚Ä¢ From the definition Œ≥(h) = Œ≥(‚àíh) for all h vectors
‚Ä¢ In most cases we suppose there is some kind of continuity in the parameter
we are dealing with. This means that the variance of the increments is
supposed to increase with the length of the vector h.
‚Ä¢ In several cases there is a certain limit in the continuity of the parameter.
This means that taking if the vector separating two points exceeds a certain
limit the variance of the increment will not increase any more.
‚Ä¢ The variogram is often discontinuous near the origin. This means that for
any h 6= 0 we have Œ≥(h) ‚â• C0 > 0. This phenomenon is the so called nugget
19

effect. The nugget effect can partly be explained by the measurement error
and partly by a random component in the parameter which is not spatially
dependent.
It is clear that the hypothesis about the existence of the variogram is the key
point of geostatistics. The first question naturally arising is: ‚ÄúCan I assume that
my parameter under study fulfils the intrinsic hypothesis ?‚Äù

Figure 3.1: Variogram cloud [mm2 ] (precipitation Jan.3, 1990)
Suppose that measurements of the parameter are taken at locations ui for
i = 1, . . . , n. Let Z(ui ) be the measured values. As a first step the impatient reader
would calculate the values (Z(ui ) ‚àí Z(u j ))2 for all the pairs formed from the measurement points ui , and would then plot them with respect to the distance (and
20

perhaps direction) separating the points. This way a so called variogram cloud
is obtained. Figure 3.1 shows such a variogram cloud. It seems to be a rather
discouraging result.

Figure 3.2: Experimental variogram [mm2 ] (precipitation Jan.3,1982)
However, the condition (2.19) did not promise that for all possible pairs the
value of (Z(ui ) ‚àí Z(u j ))2 will be close to a certain line. It is a statement on the expectation of these values. If we draw these expectations (calculated as arithmetic
means) for the same case as for which the variogram cloud was obtained (figure
3.1 ) the result is already promising as shown on figure 3.2 .

21

3.1

The experimental variogram

The variogram function has to be estimated on the basis of the available data. In
the case of a finite data set the estimation of the variogram can be made for a finite
set of vectors only.
The variogram can be estimated with the help of the following formula:
Œ≥‚àó (h) =

1
‚àë (Z(ui) ‚àí Z(u j ))2
2N(h) ui ‚àíu
j =h

(3.1)

Here N(h) is the number of pairs of locations separated by the vector h.
The calculation of the above function, called experimental variogram is
straightforward in the case of regularly spaced data points. Even in this case
the experimental variogram is calculated for a finite number of vectors. If the
points are irregularly spaced the condition for the summation ui ‚àí u j = h has to
be weakened, in order to have more pairs and not to obtain a variogram cloud as
above. This can be done by allowing a certain difference in both the angle and
the length of the vector. This means that the summation should be made over the
pairs fulfiling:
|ui ‚àí u j | ‚àí |h| ‚â§ Œµ
Angle(ui ‚àí u j , h) ‚â§ Œ¥

(3.2)

Here |.| denotes the length of a vector.
EXAMPLE 3.1 :
u

1

2

3

4

5

6

7

8

9

10

Z(u) 41.2

40.2

39.7 39.2

40.1

38.3 39.1

40.0

41.1

40.3

Table 3.1: Data points and values for example 3.1
Suppose all measurement points are alligned along the same straight line. (For
example data of the same borehole.) Also suppose that all the data points are
22

equally spaced - two neighbouring data points are separated by the distance of 1
m. Using the data given in Table 3.1 one has:
Œ≥‚àó (1) =

1
[(41.2 ‚àí 40.2)2 + (40.2 ‚àí 39.7)2 + (39.7 ‚àí 39.2)2 + (39.2 ‚àí 40.1)2 +
18
+(40.1 ‚àí 38.3)2 + (38.3 ‚àí 39.1)2 + (39.1 ‚àí 40.0)2 + (40.0 ‚àí 41.1)2 + (41.1 ‚àí 40.3)2 ] =

= 0.4917
and
Œ≥‚àó (2) =

1
[(41.2 ‚àí 39.7)2 + (40.2 ‚àí 39.2)2 + (39.7 ‚àí 40.1)2 + (39.2 ‚àí 38.3)2 +
16
+(40.1 ‚àí 39.1)2 + (38.3 ‚àí 40.0)2 + (39.1 ‚àí 41.1)2 + (40.0 ‚àí 40.3)2 ] =

= 0.756
EXAMPLE 3.2 :
In this example data of a regular grid are considered with values missing at
certain locations. The configuration of the data and the values are showed on
figure 10.3.
The experimental variogram value corresponding to the direction of the x axis,
with the length of 25 m can be calculated as:
Œ≥‚àó (25x ) =

1
[(12 ‚àí 11)2 + (13 ‚àí 12)2 + (11 ‚àí 10)2 + (10 ‚àí 11)2 + (11 ‚àí 11)2
18
+(11 ‚àí 12)2 + (12 ‚àí 10)2 + (10 ‚àí 14)2 + (14 ‚àí 13)2 ] = 1.4444

From the same data in the y direction one obtains :
Œ≥‚àó (25y ) =

1
[(10 ‚àí 11)2 + (12 ‚àí 11)2 + (11 ‚àí 11)2 + (10 ‚àí 10)2 + (10 ‚àí 10)2
18
+(11 ‚àí 13)2 + (13 ‚àí 13)2 + (13 ‚àí 11)2 + (11 ‚àí 12)2 ] = 0.6111

This example does not only show how the values of an experimental variogram are calculated, but also shows that the contribution of pairs with big differences is very important. Excluding the data point with the value 14 one has
23

10

10

11

12

10

11

10

14

13

13

11

11

13

12

6

25
? 12


11
25

-

Figure 3.3: Data configuration and values for example 3.2
Œ≥‚àó (25x ) = 0.643. If the number of pairs used for the calculation of the experimental variogram is large this unpleasent effect becomes less important.

3.1.1

Practice of experimental variogram calculation

Example showed that the estimation of an experimental variogram is very sensitive to extreme values (extreme differences). From this it can be concluded that
in order to obtain a good estimate using (3.1) several pairs corresponding to the

24

vetor h are required. In general it was suggested that at least 30 pairs are required
to get a more or less useful estimate.
Another practical problem is the selection of the vectors for which the experimental variogram values are calculated. It is quite common to select a few (2 to
8) directions (possibly depending on the site) and a so called lag distance. Then
for each direction for multiples of the lag distance experimental variogram values are calculated (allowing a tolerance both in the direction and the distance, see
equation 3.2). Of course the more directions are selected the more data are required. The calculation of the experimental variogram thus often requires several
interactive steps, changing the direction tolerances and the lag distance.
Robust estimators of the experimental variogram
As example 3.2 already pointed out the experimental variogram is very sensitive
to extreme values. This is because of the very skewed distribution of the squares of
differences. Figure 3.4 shows the histogram of squared differences corresponding
to a distance class.
It is known from statistics that in the case of skewed distributions the arithmetic mean is not the best estimator. Thus different estimators were also suggested. One of them is the formula proposed by Cressie and Hawkins (1980)
1
Œ≥‚àó (h) =
2

!4
q
1
0.494 ‚àí1
|Z(xi ) ‚àí Z(x j )| (0.457 +
)
‚àë
N(h) (i, j)‚ààR(h)
N(h)

(3.3)

This formula, based on a power transformation makes the highly skewed raw
data look more similar to the normal distribution. The fourth power brings the
formula back to the proper scale and the divisor adjusts it for bias.
The other concept a of robust estimator of the empirical semivariogram is the
trimmed mean. The basic idea of using this estimator was to combine the advantages of expressing the central tendency via mean and via median. A mean is a
good measure of central tendency if there are no extreme values in the data base.
However, the mean is very sensitive to outliers. On the other hand, the median
25

%
60 6
50
40

mean

30
20
10
0

-

?

0

40

80

120

160

200

240 mm2

Figure 3.4: Histogram of squared differences corresponding to distance class 32
km
is a robust estimator; not contaminated by the extreme observations at all. However, when evaluating the median, one goes too far in deleting observations, as
only one observed value is retained. This means that for skewed distributions,
the difference between the mean and the median are unacceptably high. Trimmed
mean is a natural trade-off combining the robustness of the median and the representativeness of the mean. It is calculated as a mean of the reduced data set,
after elimination of some (e.g. 10 per cent) highest and some lowest observed
data values. Assume, that there are n values in the sample and that the trimming
is made by removing k highest and k lowest values. Then if k/n = Œ± < 0.5, then
the trimmed mean of values v1 , . . . , vn is:
MŒ± =

1
[vk+1 + ¬∑ ¬∑ ¬∑ + vn‚àík ]
n ‚àí 2k

(3.4)

where n is the number of data points, 2k is the number of eliminated data points
26

(k highest and k lowest). This formula can be used for the determination of values
of experimental variogram in particular distance classes.
Classical
Distance

Raw data

(km)

Cressie Hawkins

With one

Raw data

outlier

With one

Trimmed mean
Raw data

outlier

With one
outlier

1.0

128.3

128.3

49.6

49.6

33.0

33.0

2.0

294.2

9903.1

152.0

220.0

120.5

120.5

3.0

405.8

405.8

298.9

298.9

196.4

196.4

4.0

484.4

6523.4

307.0

374.4

243.1

243.1

5.0

349.1

13197.7

236.8

385.7

152.8

156.8

6.0

442.5

18273.1

256.2

455.9

184.3

184.3

7.0

344.4

4674.6

255.6

295.7

165.1

165.1

8.0

435.3

22363.6

313.0

618.7

212.5

212.5

9.0

424.6

12184.0

301.0

439.7

202.4

202.4

10.0

395.6

22347.6

251.3

525.5

168.5

168.5

Table 3.2: Experimental semivariograms for chloride concentration data
Table 3.2 shows the different effect of a single extreme value on the calculated experimental variogram (calculated from 108 chloride concentration measurements). The observed value of 122 mg/l was changed to 1220 mg/l (a case
which can occur quite simply). Observe the reaction of the different estimators to
this single data change :
‚Ä¢ the classical formula resulted in an unusable experimental curve
27

‚Ä¢ the Cressie Hawkins formula shows some disturbances but seems still usable
‚Ä¢ the trimmed mean shows virtually no effects at all.

3.2

The theoretical variogram

Experimental variograms are estimates of the theoretical variogram defined in
equation (2.19). As experimental variograms are calculated for a finite number
of vectors h, variogram values for other vectors also have to be defined. This
could be done by simple linear interpolation. The disadvantage of this would be
that the piecewise linear function obtained this way would not necessarily satisfy
the conditions which have to hold for a variogram function defined in (2.19).
For example for any linear combination ‚àëni=1 Œ∏i Z(ui ), such that ‚àëni=1 Œ∏i = 0,
the variance of this combination is finite, 1 and can be calculated as:
n

n

n

Var[ ‚àë Œ∏i Z(ui )] = ‚àí ‚àë ‚àë Œ∏ j Œ∏i Œ≥(ui ‚àí u j )
i=1

(3.5)

j=1 i=1

As the variance cannot be negative the above equation already gives a necessary condition for the variogram, i.e. that for any weights Œ∏i with ‚àëni=1 Œ∏i = 0
n

n

‚àí ‚àë ‚àë Œ∏ j Œ∏i Œ≥(ui ‚àí u j ) ‚â• 0

(3.6)

j=1 i=1

It can be proved that this condition is also sufficient. Unfortunately the above
inequality can only be checked for a finite number of ui and Œ∏i combinations.
In order to relate experimental variograms to functions suitable as variograms
different theoretical models were developed. These models depending whether
the second order stationarity conditions hold or not form two groups.
1 It can be proved that only linear combinations

variance under the intrinsic hypothesis.

28

‚àëni=1 Œ∏i Z(ui ) such that ‚àëni=1 Œ∏i = 0 have a finite

If the second order stationarity conditions are met then supposing that for very
distant points the corresponding random variables are independent, one gets variograms which are constant after a certain distance. This is because if Z(u) and
Z(u + h) are independent, then C(h) = 0 and so by (2.21) one has
Œ≥(h) = C(0)

(3.7)

Variograms with this property are called variograms with a sill.
If the second order stationarity is not met (i.e. C(0) is not finite) but the intrinsic hypothesis is true then we get variogram models without a sill.
Finally positive linear combinations of the previous variogram models also
fulfil the necessary and sufficient conditions for a function to be a variogram.
These are the so called complex models.

3.2.1

Variogram models with a sill

There are four commonly used elementary types of variograms with a sill. Positive
linear combinations of these models are also variograms with a sill.
The pure nugget effect
The pure nugget effect corresponds to the case when there is no correlation between the random variables corresponding to different locations. This means that
the value of the variogram is zero if h is zero, otherwise it is equal to the same
constant which is C(0) the variance of the random variable. The formula is:
Œ≥(h) = 0 if h = 0
Œ≥(h) = C if h > 0
Figure 3.5 shows the graph of a pure nugget effect variogram.

29

(3.8)

6

c

r

-

Figure 3.5: The pure nugget effect
The spherical variogram
This is the most commonly used type of variogram. It can be described by two
parameters, the range and the sill. The range a is the distance which separates
the correlated and the uncorrelated random variables. If two points u0 and u00
are separated by a distance bigger than this range then the corresponding random
variables Z(u0 ) and Z(u00 ) are independent. Conversely if their distance is less
than the range then Z(u0 ) and Z(u00 ) are not independent. The value of the sill C is
the value of the variogram for distances bigger than the range. It is equal to C(0),
the variance of the random variable. This implies C > 0. The formula is:
3 h 1 h3
‚àí
) if h ‚â§ a
2 a 2 a3
Œ≥(h) = C if h > a

Œ≥(h) = C(

(3.9)

Figure 3.6 shows the graph of a spherical variogram.
The exponential variogram
As the spherical variogram the exponential variogram is also described with the
help of two parameters. One of them is the sill, which equals C(0) as for the
30

6
((
!
!
"

6

"




sill

#
,
,
,
,

range



?

-

Figure 3.6: The spherical variogram
spherical variogram. The other parameter corresponds again to the change of
variogram values with respect to the distance. In this case there is no special
distance separating the correlated and the uncorrelated random variables as in
the spherical case. All random variables are supposed to be non independent.
However there is an effective range 3a such that random variables corresponding
to points more distant than 3a can be considered as independent. The formula is:
h

Œ≥(h) = C(1 ‚àí e‚àí a )

(3.10)

Here C is nonnegative. Figure 3.7 shows the graph of an exponential variogram.
The gaussian variogram
The gaussian variogram is also characterized by two parameters. The sill C is
again equal to C(0), the variance of the random variable. The parameter a is again
related to the effective range of the variogram. As in the case of the exponential variogram there is no theoretical limit between correlated and non correlated
‚àö
random variables. The effective range in this case is 3a. The formula is:
2

‚àíh

Œ≥(h) = C(1 ‚àí e a2 )
31

(3.11)

6
((((

!



"

,
%
%






-

Figure 3.7: The exponential variogram
C is positive. Figure 3.8 shows the graph of a gaussian variogram.
Note the difference between the gaussian and the exponential and spherical
variograms in the neighbourhood of the origin. The exponential and the spherical
variograms show a linear increase, while the increase of the gaussian is much
smoother - showing a quadratic type of behavoir near 0.

3.2.2

Variogram models without sill

If the regionalized variable does not fulfil the second order stationarity hypothesis
but is intrinsic, then its variogram can show an unlimited increase.
Models hŒª
The function defined as:
Œ≥(h) = ChŒª for 0 < Œª < 2

(3.12)

represents a valid variogram model. The case Œª = 1 is the linear variogram, and
it is quite often used in geostatistics. Figure 3.9 shows hŒª models for different Œª
values.
32

(

(((
((((

!

"

6



,

%
%
%
%
,


(

-

Figure 3.8: The gaussian variogram
Complex models
All previously listed variogram models satisfy (3.6). Unfortunately these models
can not always describe the variability of the regionalized variable under study.
Combinations of the previous models enrich the set of theoretical variograms.
It can be shown that if Œ≥1 (h), . . . , Œ≥K (h) are all variogram models satisfying
(3.6) and c1 , . . . , cK are nonnegative numbers then:
K

Œ≥(h) = ‚àë ck Œ≥k (h)

(3.13)

k=1

is also a function satisfying (3.6), and thus an appropriate variogram model. Formula (3.13) makes it possible to combine models of different range describing the
different types of variability of the regionalized variable. The most commonly
used complex models are the combinations of a nugget effect and a simple model
(like spherical).
Complex models also occur in the case when the variogram of a linear combination of regionalized variables is calculated. Suppose Zi (u) and Z j (v) are inde-

33

!!
!!
!
((
!

6
!!

!!
!!

Œª = 0.5

!!!


!

!!


!
!


!!

!

!
!!
!!
!
!

!

!!
Œª=1
"
!
!

!
!
!!
!
 !
!!

-

Figure 3.9: The hŒª variograms
pendent for i 6= j. Then for defining:
I

Z(u) = ‚àë ci Zi (u)

(3.14)

i=1

the variogram for Z can be calculated with the help of the variograms of the Zi -s.
Namely:
"

#

I

I

i=1

i=1

Œ≥(h) = E ( ‚àë bi Zi (u + h) ‚àí ‚àë bi Zi (u))2 =
"
=E

#

I

I

‚àë bi(Zi(u + h) ‚àí Zi(u))2 = ‚àë b2i Œ≥i(h)

i=1

(3.15)

i=1

Here Œ≥i (h) is the variogram for Zi .
This formula can be useful for certain non natural variables, like for example
if the value of an ore is proportional to its contents of some of its components.

3.3

Variogram fitting

On the previous pages several methods and practical remarks were given for the
calculation of experimental variograms. As pointed out these curves do not satisfy
34

the statistical properties of a variogram. Thus a theoretical curve has to be fitted to
the experimental one. The previous section described several possible theoretical
models, the next step is the procedure of fitting one of them to the experimental.
There are several different approaches to do this. First we have to mention
that theoretical studies yielded the conclusion that the values of an experimental
variogram corresponding to distant pairs are unreliable. It turned out that only
the first few values can be used for finding a theoretical fit. As a rule of thumb
variogram values corresponding to distances greater then the half of the greatest
distance between two points in D are not considered for further use.
The most common method for fitting a variogram is doing it ‚Äùby eye‚Äù. This
means that one plots the useful part of the experimental variogram and then tries
to find a linear combination of theoretical models (i.e. a complex model) which
produces a graph close to the experimental one. The disadvantage of this method
is clear - it is not statistically justified and different experts can fit different theoretical models to the same experimental variogram. However, the great advantage of
this method is that plotting the experimental curve one can detect many problems
of the data set and the calculations. Extremely high or low variogram values must
have reasons to be so and can be traced back. Errors of the data set (e.g. mistyping) can often be detected this way. Also the intrinsic hypothesis can partly be
checked by looking at the experimental variogram. Curves increasing in certain
directions and steady in others often indicate the existence of trends. Inhomogeneities of the data set can also cause problems and be detected this way. Also
the correct selection of the lag and the tolerance values can be checked this way.
Engineering and geological information can be used in this procedure by implicit
weighting of the variogram values.
There are authors who suggest that the theoretical variogram should be fitted
by a standard least squares approach. There are several problems with this approach: The method is ‚Äùblind‚Äù, the previously mentioned errors cannot be found.
Another disadvantage is that this method assumes that the errors (the deviation
of the theoretical from the experimental) are supposed to be independent. This

35

Figure 3.10: Experimental variogram with an easy fit
assumption is generally not met.
Other methods like the maximum likelihood fit were also developed. Using a
maximum likelihood method one has to postulate distributions for different distance classes. These distributions are to describe the deviations of the square of
the difference of two parameter values from the theoretical model. For each pair
a probability depending on the parameter values can be calculated. The maximum likelihood estimator is that parameter combination which yields the highest
product of these probabilities. This estimator is also ‚Äùblind‚Äù as the least squares
method. It also supposes independence between the different squares corresponding to different data pairs - which is generally not met.
36

Figure 3.11: Experimental variogram with a difficult fit
Figure 3.10 shows an ‚Äúeasy‚Äù by eye fit, figure 3.11 shows a ‚Äúdifficult‚Äù case.

3.4

Isotropy ‚Äî anisotropy

The random function is called isotropic if its variogram depends only on the
length of the vector h. In this case the experimental variogram can be calculated
with the only limiting condition |ui ‚àí u j | = |h|.
Isotropy of a random function can partly be checked if there is a sufficient
amount of ‚Äùwell spaced‚Äù (for example not alligned) data. In this case experimental
variograms corresponding to different directions can be calculated and compared.
37

However, in many cases especially in the case of small data sets this assumption
has to be made in order to have enough data for each selected class. If a random
function is not isotropic, then it can show different types of anisotropy.

3.4.1

Geometric anisotropy

The regionalized variable has a geometric anisotropy if there is a coordinate transformation T such that Z(u0 ) = Z(Tu) is isotropic. This means that for geometric
anisotropy a simple transformation of the coordinates leads to a case where only
distances (in the new coordinate system) play a role.
The natural question arises: how does one find such a transformation? The
existence of such a transformation implies that the value of the sill (if there is any)
is the same for each direction. Ranges corresponding to different directions can
then be plotted. If these ranges fall on an ellipse, then a rotation and a subsequent
shrinking will be the appropriate transformation T . The corresponding geometric
transformation is described with two parameters:
œï= the angle between the x coordinate and the main axes of the anisotropy (ellipse)
Œª= the ratio of the two orthogonal ranges representing the highest and the lowest
variability
The corresponding transformation has the mathematical form:
x0 = Œª(x cos œï + y sin œï)
y0 = ‚àíx sin œï + y cos œï

(3.16)

with (x, y) being the coordinates in the original and (x0 , y0 ) those in the transformed
system. Calculations then can be carried out in the transformed system as in the
isotropic case.
In three dimensions the ellipse is replaced by an ellipsoid. In practice the
variability in the vertical direction is much higher then in horizontal directions,
leading to a strong anisoptropy.
38

3.4.2

Zonal anisotropy

If the ranges do not fall on an ellipse, or even the sill values are different then it
is a zonal anisotropy . In the case of a zonal anisotropy a complex model has
to be fitted. The individual terms of the complex model show different geometric
anisotropies, and some of them might change in only one direction.

39

Chapter 4
Ordinary Kriging
Variograms provide a lot of information about the parameter under study, but essentially they are tools for other geostatistical calculations. One of the possible
(and perhaps the most important) use of variograms is in the estimation of parameter values at unsampled locations, and/or the estimation of the average of the
parameter over a certain area. The simplest geostatistical procedure doing this is
ordinary kriging. Ordinary kriging is the procedure which is most widely known
(and often labeled by the single word kriging).

4.1

Point kriging

One of the most common interpolation (and extrapolation) problems is the estimation of a parameter at unsampled location u. In the framework of regionalized
variables this can be done with the help of the procedure labeled point kriging.
A linear estimator, i.e. a linear combination of the values of the regionalized
variable at known locations, is to be found. This means that the estimator is of the
form:

n

Z ‚àó (u) = ‚àë Œªi Z(ui )

(4.1)

i=1

There are infinitely many possible choices for the weights Œªi . It is desirable to
40

select them in order to have an unbiased estimator which also has the smallest
possible estimation variance. Using the second order stationarity or the intrinsic
hypothesis one has:
E[Z(u)] = m for all u ‚àà D

(4.2)

This means for the linear estimator
n

E[Z (u)] = ‚àë Œªi E[Z(ui )] = m
‚àó

(4.3)

i=1

so the weights have to fulfil:

n

‚àë Œªi = 1

(4.4)

i=1

This is the so called unbiasedness condition. Using the second order stationarity
hypothesis the estimation variance can be calculated with the help of the covariance function C(h) as:
"

#

n

œÉ2 (u) = Var[Z(u) ‚àí Z ‚àó (u)] = E (Z(u) ‚àí ‚àë Œªi Z(ui ))2 =
i=1

"

n

n

#

n

= E Z(u)2 + ‚àë ‚àë Œªi Œª j Z(ui )Z(u j ) ‚àí 2 ‚àë Œªi Z(ui )Z(u) =
i=1 j=1

i=1

n

n

n

j=1 i=1

i=1

= C(0) + ‚àë ‚àë Œª j ŒªiC(ui ‚àí u j ) ‚àí 2 ‚àë ŒªiC(ui ‚àí u)

(4.5)

The estimation variance is a quadratic function of the weights Œªi . The best linear
unbiased estimator (BLUE) is the one which minimizes the estimation variance
with respect to the unbiasedness condition. This constrained optimization problem can be solved with the help of a Lagrange multiplier ¬µ. The function
!
œÉ (u) ‚àí 2¬µ
2

n

‚àë Œªi ‚àí 1

(4.6)

i=1

is to be minimized. Using the partial derivatives with respect to the unknown
parameters Œªi and ¬µ one has to solve the linear equation system:
n

‚àë Œª jC(ui ‚àí u j ) ‚àí ¬µ = C(ui ‚àí u) i = 1, . . . , n

j=1

41

n

‚àë Œªj = 1

(4.7)

j=1

Solving (4.7) yields the weights Œªi for the linear estimator. The equation system
(4.7) is called kriging system in terms of covariances.
If the intrinsic hypothesis is used the estimation variance can be expressed
with the help of the variogram:
n

n

n

j=1 i=1

i=1

œÉ2 (u) = Var[Z(u) ‚àí Z ‚àó (u)] = ‚àí ‚àë ‚àë Œª j Œªi Œ≥(ui ‚àí u j ) + 2 ‚àë Œªi Œ≥(ui ‚àí u)

(4.8)

The goal is to minimize œÉ2 (u) under the unbiasedness conditions. This optimization problem can also be solved with the help of a linear equation system. Introducing the Lagrange multiplier ¬µ the weights that minimize œÉ2 (u) are the solution
of:
n

‚àë Œª j Œ≥(ui ‚àí u j ) + ¬µ = Œ≥(ui ‚àí u) i = 1, . . . , n

j=1

n

‚àë Œªj = 1

(4.9)

j=1

The above equation system is called kriging system, the weights Œªi are the kriging
weights. The minimal estimation variance can be obtained by substituting the
kriging weights into (4.8). This variance is called kriging variance œÉ2K (u). It can
be proved that :

n

œÉ2K (u) = ‚àë Œªi Œ≥(ui ‚àí u) + ¬µ

(4.10)

i=1

This equation is of no theoretical interest, but it simplifies the calculation of the
estimation variance.
EXAMPLE 4.1 :
Suppose that using two points on a straight line the value at a third point is
to be estimated. The points are u1 = 1 and u2 = ‚àí2. The point for which the
estimation is to be done is u = 0. Figure 4.1 shows the configuration. Let the
42

measurement values be Z(u1 ) = 2 and Z(u2 ) = 4. Suppose the variogram is linear
Œ≥(h) = h.

u2

u

u1

Figure 4.1: Data configuration for example 4.1
The kriging equations are:
0Œª1 + 3Œª2 + ¬µ = 1
3Œª1 + 0Œª2 + ¬µ = 2
Œª1 + Œª2 = 1

(4.11)

From this one has Œª1 = 0.6667, Œª2 = 0.3333 and ¬µ = 0. Thus œÉ2 = 1.3333 and
Z ‚àó (u) = 2.6667. It is clear that kriging yielded the same weights as linear interpolation or inverse distance method.
Suppose the configuration is changed and u2 is moved to the other side of the
origin: u2 = 2. Figure 4.2 shows the modified configuration.

u

u1

u2

Figure 4.2: Modified data configuration for example 4.1
The kriging equations are:
0Œª1 + 1Œª2 + ¬µ = 1
43

1Œª1 + 0Œª2 + ¬µ = 2
Œª1 + Œª2 = 1

(4.12)

From this one has Œª1 = 1.0, Œª2 = 0.0 and ¬µ = 1.0. Thus œÉ2 = 2.0 and Z ‚àó (u) = 2.0.
The result is different from the previous, but it would not be different in the case
of the inverse distance method. This example demonstrates that the data configuration plays an important role in kriging. The increased estimation variance shows
that the extrapolation in the second case is more uncertain than the interpolation
in the first.

4.2

Block kriging

Quite often applications require average values of the parameter over certain areas,
instead of point values. These averages could be calculated using point kriging for
a great number of points in the area and taking their average. A simpler way of
doing this is using block kriging.
Suppose the average of the parameter over a volume V (block) in the domain
D is to be estimated.

1
Z(V ) =
|V |

Z

Z(u) du

(4.13)

Z ‚àó (V ) = ‚àë Œªi Z(ui )

(4.14)

‚à®

Again a linear estimator of the form :
n

i=1

is to be found. The unbiasedness condition leads again to:
n

‚àë Œªi = 1

(4.15)

i=1

The estimation variance in this case is:
n

n

n

j=1 i=1

i=1

œÉ2 (V ) = Var[Z(V ) ‚àí Z ‚àó (V )] = ‚àíŒ≥(V,V ) ‚àí ‚àë ‚àë Œª j Œªi Œ≥(ui ‚àí u j ) + 2 ‚àë Œªi Œ≥(ui ,V )
(4.16)
44

here Œ≥ is the average variogram value:
1
Œ≥(ui ,V ) =
|V |
1
Œ≥(V,V ) =
|V |

Z
‚à®

Œ≥(ui ‚àí u) du

(4.17)

Œ≥(u ‚àí v) du dv

(4.18)

Z Z
‚à® ‚à®

The minimization of œÉ2 (V ) under the unbiasedness condition leads to the linear
equation system:
n

‚àë Œª j Œ≥(ui ‚àí u j ) + ¬µ = Œ≥(ui,V ) i = 1, . . . , n

j=1

n

‚àë Œªj = 1

(4.19)

j=1

EXAMPLE 4.2 :
Suppose that for the same configuration as in the first part of example 4.1
instead of point u = 0 the average over the interval [‚àí0.5, 0.5] is to be found.
Block kriging is applied for the estimation. The left hand side of the equation
system is identical to the point kriging case. The right hand side is:
Œ≥(u1 ,V ) =
Œ≥(u2 ,V ) =

Z +0.5

|t ‚àí 1| dt = 1

‚àí0.5

Z +0.5

|t + 2| dt = 2

‚àí0.5

Thus the kriging equations are again:
0Œª1 + 3Œª2 + ¬µ = 1
3Œª1 + 0Œª2 + ¬µ = 2
Œª1 + Œª2 = 1

(4.20)

From this one has Œª1 = 0.6667, Œª2 = 0.3333 and ¬µ = 0. To calculate the estimation
variance one also needs the value of Œ≥(V,V ). This is:
Œ≥(V,V ) =

Z +0.5 Z +0.5
‚àí0.5

|t ‚àí s| dt ds = 2

‚àí0.5

Z +0.5 Z s
‚àí0.5

45

‚àí0.5

s ‚àí t dt ds =

1
3

Thus œÉ2 = 1.000 and Z ‚àó (V ) = 2.6667. For this case block kriging yielded the
same weights as point kriging, but the estimation variance is smaller using block
kriging. (The weights calculated for the center of a block using point kriging are
not necessarily equal to the weights corresponding to the block !)

4.3

Properties of ordinary kriging

The kriging estimator has several interesting partly advantageous and partly disadvantageous properties. First some general properties are listed, then the relationship between kriging and the variogram is investigated.

4.3.1 Kriging as an interpolator
Kriging is an interpolation (and extrapolation) technique. Important properties of
the kriging interpolator are:
1. Kriging is an exact interpolator: for each observation point ui Z(ui ) =
Z ‚àó (ui ), and the corresponding estimation variance is zero. This is because
taking Œªi = 1 and Œª j = 0 if i 6= j the kriging equations are satisfied.
2. Kriging weights are calculated with the help of the variogram and the locations of the measurement points and the point to be estimated. Not only
distances between measurement points and the point to be estimated are
considered but also the relative position of the measurement points.
3. Kriging weights sum up to 1, but they can also be negative. Thus the usual
hypothesis
max{Z(ui )} ‚â§ Z ‚àó (u) ‚â§ min{Z(ui )}
is not true.
4. Kriging weights are not influenced by the measurement values. If the same
configuration appears at two different locations the kriging weights will be
46

the same, independently from the measured values. The measured values
influence the variogramm which is the basis for the calculation of the kriging weights.
5. Kriging weights show a screening effect, distant points receive lower weights
if closer measurements are available. This effect is demonstrated in example
4.3.

47

EXAMPLE 4.3 :
6 s

4 s

3 s

5 s

d

1 s

2 s

Figure 4.3: Data configuration for example 4.3
Suppose the value of the regionalized variable has to be estimated at the point
(0,0) with the help of a subset of the points listed in table 4.1. The configuration
is also displayed on figure 4.3. The variogram is known :
Œ≥(h) = C0 +C1 Œ≥S (h) for h > 0

(4.21)

where Œ≥S (h) is a spherical model with a range a = 10. C0 = 0.05 is the nugget
effect and C1 = 0.20.
Three different cases are considered:
1. kriging using points 1,2,3 and 4
2. kriging using points 1,2,3,4 and 5
48

No.

x

y

1

-1.00

-1.00

2

1.00

-1.00

3

2.00

2.00

4

-1.00

2.00

5

1.00

1.00

6

-1.10

1.90

Table 4.1: Different possible measurement locations
3. kriging using points 1,2,3,4 and 6.
Weights calculated for each case are shown in table 4.2.
Comparing case 1 and case 2 one can see that the weight corresponding to
point 3 decreased substantially because of the inclusion of point 5. The other
weights did not change drastically.
In case 3 part of the weight associated to point 4 was shifted to point 6, the
other weights were much less influenced.
These two examples show that kriging filters out the useful information and
assigns less weight to points which are close to other points or which are screened
by other points.

4.3.2

Kriging and the variogram

As the estimation variance is calculated with the help of the variogram, and the
kriging equations also contain variogram values it is obvious that the variogram
plays a central role in kriging.
Using the variogram kriging delivers not only estimated values but also pro49

Weights
Point

Case 1

Case 2

Case 3

1

0.322

0.294

0.304

2

0.317

0.255

0.311

3

0.144

0.047

0.130

4

0.217

0.163

0.123

5

‚Äî

0.240

‚Äî

6

‚Äî

‚Äî

0.132

Table 4.2: Kriging weights for the three different cases
vides corresponding estimation variances. (Unfortunately these weights only depend on the data configuration and the variogram but not on the actual data values.) These estimation variances express the quality of the interpolation, high estimation variance means uncertain interpolation ‚Äî low estimation variance shows
good interpolation. Estimation variances are often used as normal error variances.
As mentioned previously the estimation variance is zero if the parameter is
to be estimated at a measurement point location. In the neighbourhood the estimation variance is low (depending on the variogram) and as the distance from
measurement points increases so does the estimation variance. Points (or blocks)
with high estimation variances indicate areas where the estimation is uncertain.
Comparing estimation variances obtained using point and block kriging one
can see that the latter are substantially smaller. This is because of the additional
term Œ≥(V,V ) for the block variances. As Œ≥(V,V ) increases with the block dimensions the estimation variance decreases. This fact is in full agreement with the fact
known from statistics, that a mean can be estimated with much higher accuracy
than an individual value.
50

EXAMPLE 4.4 :
To show the role of the nugget effect consider the data of example 4.3. Three
different variogram models were used to calculate the kriging weights.
Œ≥(h) = C0 +C1 Œ≥S (h) for h > 0

(4.22)

where Œ≥S (h) is a spherical model with a range a = 10. For Œ≥1 C0 = 0.05 is the
nugget effect and C1 = 0.20. For Œ≥2 C0 = 0.20 is the nugget effect and C1 = 0.05.
For Œ≥3 C0 = 0.0 is the nugget effect and C1 = 0.25.
Weights
Point

Œ≥1

Œ≥2

Œ≥3

1

0.322

0.265

0.341

2

0.317

0.262

0.352

3

0.144

0.230

0.098

4

0.217

0.243

0.210

Table 4.3: Kriging weights for the three different variograms
Kriging weights for the three different models are shown in table 4.3. Note
that for Œ≥2 , where the nugget value is increased, the weights are almost equal.
The highest weight differences are for the case of Œ≥3 , where there is no nugget
effect. This example shows that a high nugget effect leads to estimators around
the sample mean.
If the variogram Œ≥(h) is replaced by its constant multiple cŒ≥(h) then the kriging
weights do not change. This is a consequence of (4.8), as the estimation variance
is also multipled by the same constant, thus the minimum variance is realized
using the same weights.
51

If Œ≥(h) is replaced by another variogram which is close to it, then the kriging
weights do not change substantially. Unfortunately the possible changes depend
both on the configuration of the data points and the actual data values.

4.4

Practice of kriging

4.4.1

Selection of the neighbourhood

As example 4.3 already demonstrated the screening property of kriging leads to
small weights for distant samples. On the other hand the intrinsic hypothesis
is supposed to hold locally within a certain distance. These two facts and the
numerical efficiency of the solution imply that only the closest few samples should
be used in kriging.
Usually the points used for the kriging of a point or block are selected within a
certain distance (usually around the range) with taking into account the anisotropy.
If there are still too many points in such a neighbourhood the closest n are taken,
where n is a prescribed limit.
It is important to notice that the above procedure fails to work properly if the
points are very irregularly spaced. In such a case different criteria have to be
given. (for example directional search)
In three dimensions when the number of points is too high a regrouping of the
points into blocks and then kriging from these blocks can reduce the computations.

4.4.2

Kriging with a ‚Äúfalse‚Äù variogram

Kriging is sometimes used also without the calculation of an experimental variogram, but only assuming a theoretical model. As mentioned above the selection
of the variogram parameters can influence the kriging results. Usually a complex
model of two elements a nugget effect and a simple model (spherical, exponential, gaussian or linear) is assumed. As the multiplication of the variogram by a

52

constant does not influence the kriging results, the most important factor in this
case is the relative nugget effect (= sill divided by the nugget effect).
In any case an interpolator having the above mentioned properties is used. The
estimation variances calculated without a proper variogram will be meaningless.

4.5

Cross validation

As previously mentioned the uniqueness of the realization makes the use of statistical test in geostatistics quite difficult. However, the subjective ‚Äúby eye‚Äù fit
of theoretical variograms should be checked somehow to reduce its effects. One
possible way of doing this is the so called ‚Äúcross validation‚Äù. This procedure tests
the variogram by a procedure where it is most often used, namely the kriging
procedure.
For each measurement location ui the values are estimated (using kriging) as if
they were unknown. This estimator is now denoted by Z v (ui ) and the corresponding kriging standard deviation is œÉv (ui ). Then the estimated values are compared
with the true values Z(ui ). If the kriging standard deviation can be interpreted as
an estimation error with normal distribution then
S(ui ) =

Z v (ui ) ‚àí Z(ui )
œÉv (ui )

(4.23)

should be normally distributed with 0 mean and 1 as standard deviation (N(0, 1)).
The mean indicates whether the estimator is unbiased or not, the variance of S
indicates the correctness of the kriging standard deviations.
The calculation of the S(ui ) values with the fitted variogram is the first test
of the appropriateness of the fit. If the distribution is different from N(0, 1) then
variation of the coefficients can improve the fit.
Cross validation techniques can be used to detect outliers of the measurement
values.

53

4.6

Kriging with uncertain data

It is quite often the case that the same parameter is measured or estimated with
the help of different methods. If these methods yield different accuracies the
corresponding measurement values should also be handled differently.
Suppose that for each point ui there is an unknown error term Œµ(ui ) having the
following properties:
1. Unbiased :
E[Œµ(ui )] = 0

(4.24)

E[Œµ(ui )Œµ(u j )] = 0 if i 6= j

(4.25)

2. Uncorrelated :

3. Uncorrelated with the parameter value:
E[Œµ(ui )Z(ui )] = 0

(4.26)

For convenience the estimation for a block V is given here, but the same applies
for point values, too. The linear estimator in this case is:
n

Z (V ) = ‚àë Œªi (Z(ui ) + Œµ(ui ))
‚àó

(4.27)

i=1

The unbiasedness condition has to hold as in the case of ordinary kriging. So :
n

‚àë Œªi = 1

(4.28)

i=1

The estimation variance is:
n

n

n

n

j=1 i=1

i=1

i=1

Var[Z(V )‚àíZ ‚àó (V )] = ‚àíŒ≥(V,V )‚àí ‚àë ‚àë Œª j Œªi Œ≥(ui ‚àíu j )+2 ‚àë Œªi Œ≥(ui ,V )+ ‚àë Œª2i E[Œµ(ui )2 ]
(4.29)

54

To minimize the estimation variance an equation system similar to the ordinary
kriging system has to be solved. Namely:
n

‚àë Œª j Œ≥(ui ‚àí u j ) + ŒªiE[Œµ(ui)2] + ¬µ = Œ≥(ui,V ) i = 1, . . . , n

j=1

n

‚àë Œªj = 1

(4.30)

j=1

To illustrate the above methodology consider the following example:
EXAMPLE 4.5 :
Hydraulic conductivity is measured with different methods:
1. Direct measurements
2. Gravimetric measurements
3. Nuclear measurements
In the case of gravimetric and nuclear measurements the logarithm of the hydraulic conductivity is estimated from the measured water content and the dry
density with the help of a nonlinear regression. The regression error for gravimetric measurements is D[ŒµG ] = 0.30997, for nuclear measurements D[ŒµN ] = 0.32828.
The measurement data are listed in table 4.4. The average log K value of the
square block V with opposite corner coordinates (0,0) and (3,3) is to be estimated.
Figure 4.4 shows the data configuration.
The variogram of log K was estimated on the basis of other measurement data,
and a theoretical model was fitted:
Œ≥(h) = C0 +C1 Œ≥S (h) for h > 0

(4.31)

where Œ≥S (h) is a spherical model with a range a = 6 m. C0 = 0.05 is the nugget

55

No.

x

y

log K

Measurement type

1

-1.00

-1.00

-7.07

Direct

2

4.00

1.50

-7.89

Direct

3

-1.00

1.50

-6.41

Gravimetric

4

4.00

-1.00

-6.84

Gravimetric

5

4.00

4.00

-7.69

Nuclear

6

1.50

-1.00

-7.94

Nuclear

Table 4.4: Different log K measurement data
effect and C1 = 0.15. The equation system (4.30) for this case is:
+ 0.199Œª2 + 0.138Œª3 + 0.194Œª4 + 0.200Œª5 + 0.138Œª6 + ¬µ = 0.167
0.199Œª1 +

+ 0.194Œª3 + 0.138Œª4 + 0.138Œª5 + 0.167Œª6 + ¬µ = 0.141

0.138Œª1 + 0.194Œª2 ‚àí 0.096Œª3 + 0.199Œª4 + 0.199Œª5 + 0.167Œª6 + ¬µ = 0.141
0.194Œª1 + 0.138Œª2 + 0.199Œª3 ‚àí 0.096Œª4 + 0.194Œª5 + 0.138Œª6 + ¬µ = 0.167
0.200Œª1 + 0.138Œª2 + 0.199Œª3 + 0.194Œª4 ‚àí 0.108Œª5 + 0.199Œª6 + ¬µ = 0.167
0.138Œª1 + 0.167Œª2 + 0.167Œª3 + 0.138Œª4 + 0.199Œª5 ‚àí 0.108Œª6 + ¬µ = 0.141
Œª1 +

Œª2 +

Œª3 +

Œª4 +

Œª5 +

Œª6 +

The solution of the equation system is shown in table 4.5. The value of Œ≥(V,V ) is
0.1003, the estimation variance is 0.0778 and the estimated log K value is -7.36.
In the case of ordinary kriging without error terms the kriging equations would
be the same except the main diagonal being zero. The solution in this case is can
also be found in table 4.5.
56

=

1

5

3 s

1 c

V

6

2 c

4 s

Figure 4.4: Data configuration for example 4.5
Note that observations 2,3, and 6 have similar weights as they are the closest
observations to the block to be estimated. Weights for the direct measurements
decreased, as all measurements are handled equally in this case.

57

Weights

Kriging with

Point kriging

uncertainty
Œª1

0.147

0.042

Œª2

0.303

0.252

Œª3

0.210

0.294

Œª4

0.077

0.051

Œª5

0.108

0.126

Œª6

0.155

0.235

¬µ

0.020

0.009

Table 4.5: Weight calculated using uncertain and exact data

58

4.7

Simple Kriging

The Ordinary Kriging procedure is based on the assumption that the expected
value of the underlying process is the same over the domain under study. The
knowledge of this constant was not neccessary. Simple kriging is an alternative to
OK supposing the mean m(u) is known (not neccessarily constant) in the whole
domain. In this case the estimator: Again a linear estimator of the form :
n

Z ‚àó (u) = m(u) + ‚àë Œªi (Z(ui ) ‚àí m(ui ))

(4.32)

i=1

is to be found. The unbiasedness condition means in this case:
n

E[Z ‚àó (u) ‚àí Z(u)] = m(u) + ‚àë Œªi E[Z(ui ) ‚àí m(ui )] ‚àí m(u) = 0

(4.33)

i=1

This condition does not imply any additional constraints. The variance of the
estimator is expressed using the covariance function C:
Var[Z ‚àó (u) ‚àí Z(u)] = E[Z ‚àó (u)2 + Z(u)2 ‚àí 2Z ‚àó (u)Z(u)] =
n

n

n

i=1 j=1

i=1

‚àë ‚àë ŒªiŒª jC(ui ‚àí u j ) +C(0) ‚àí 2 ‚àë ŒªiC(ui ‚àí u)

(4.34)

The estimation variance is minimal if:
‚àÇVar[Z ‚àó (u) ‚àí Z(u)]
=0
‚àÇŒªi

(4.35)

This leads to the simple kriging equation system:
n

‚àë Œª jC(ui ‚àí u j ) = C(ui ‚àí u)

j=1

59

(4.36)

Chapter 5
Non stationary methods
Unfortunately many natural parameters do not fulfil the intrinsic hypothesis, because of a known systematic change in the parameter value. For example groundwater head is a parameter which usually has a systematic drift, and thus should
not be investigated with stationary methods. Systematic changes contaminate the
experimental variogram and lead to unacceptable results. Some known methods
are presented in this chapter to deal with this problem.
Suppose that the first assumption of the intrinsic hypothesis is not met. Namely
instead of a constant expectation there is a drift present. It is supposed the the difference between the regionalized variable and the drift is intrinsic. Formally:
Z(u) = f (u) +Y (u)

(5.1)

where Y (u) is intrinsic and E[Y (u)] = 0.
The most common method for estimating a drift is the use of least squares
trend fitting. The assumption for fitting is that the residuals are independent. This
contradicts the basic hypothesis, namely that a the regionalized variable is the
sum of a deterministic drift and an intrinsic residual. (It would be true only if the
residual had a pure nugget effect variogram.)
In order to deal with the drift four different methods could have been used.
‚Ä¢ Universal kriging
60

‚Ä¢ Intrinsic random functions of order k (IRF-k)
‚Ä¢ Residual kriging
‚Ä¢ External Drift Kriging.
A main difference between these methods is that universal kriging and residual
kriging are based on a more or less explicit estimation of the drift, while IRF-k
method only attempts to filter out its effect.

5.1

Universal kriging

The main problem in nonstationary cases is that the estimation of the drift would
require the knowledge of the variogram, but the estimation of the variogram requires the knowledge of the drift. Universal kriging is a method where the drift
paramaters are estimated in an iterative way, in order to estimate the variogram.
Later in the kriging process this drift is not explicitly used, instead the effect of
such a drift is filtered out.
The variogram is insensitive to constants added to the regionalized variable.
Thus the drift f (u) is be to found up to an additive constant. Suppose that the drift
is of the form:

S

f (u) = ‚àë bs fs (u)

(5.2)

s=0

where f0 (u) = 1 and coefficients bs are unknown, and have to be found for s > 0.
It is supposed that 5.2 does not hold for the entire domain but only for neighbourhoods. Thus the coefficients are also ‚Äúlocal‚Äù. The next equations refer to the
case of one neighbourhood. The estimators of the coefficients are taken as linear
combinations of the measured values:
n

Bs = ‚àë di,s Z(ui )
i=1

61

(5.3)

These estimators should be unbiased, which means that:
n

E[Bs ] = bs = ‚àë di,s E[Z(ui )]

(5.4)

i=1

Using (5.2) one has:
n

S

i=1

q=1

S

n

q=1

i=1

bs = ‚àë di,s ‚àë bq fq (ui )

(5.5)

From this it follows that:
bs = ‚àë bq ‚àë di,s fq (ui )

(5.6)

If the functions fs (u) are linearly independent then from (5.6) it follows that:
Ô£±
Ô£¥
Ô£≤ 1 if q = s
n
(5.7)
‚àë di,s fq(ui) Ô£¥
Ô£≥ 0 if q 6= s
i=1
The variance of the estimator is
"

n

Var[Bs ] = Var

#

‚àë di,sZ(ui)

(5.8)

i=1

as only those linear combinations have a finite variance for which
n

‚àë di,s = 0

(5.9)

i=1

Using this one can calculate the estimation variance:
n

n

Var[Bs ] = ‚àë ‚àë di,s d j,s Œ≥(ui ‚àí u j )

(5.10)

i=1 j=1

This estimation variance is to be minimized under the unbiasedness conditions
5.7 . Introducing the Lagrange multipliers this leads to a set of equation systems
similar to the kriging system:
62

n

S

j=1

q=1

‚àë d j,sŒ≥(ui ‚àí u j ) + ¬µ0,s + ‚àë ¬µq,s fs(u) = 0 for i = 1, . . . , n
n

‚àë di,s = 0

i=1
n

Ô£±
Ô£¥
Ô£≤ 1

if q = s

i=1

Ô£¥
Ô£≥ 0

if q 6= s

‚àë di,s fq(ui)

(5.11)

Solving the above equation systems for s = 1, . . . , S one obtains the coefficients
di,s and from this the bs -s. The only problem with the above approach is that the
calculation of the coefficients requires also the knowledge of the variogram. An
iterative procedure can help to overcome this problem.
1. Determine the type of the drift (usually order of the polynomial).
2. Take a theoretical variogram Œ≥, and calculate the drift coefficients.
3. Calculate the experimental variogram of the residuals.
4. Compare the theoretical variogram taken in step 2 and the calculated experimental. If the correspondance between the two curves is good then stop,
else repeat from step 2 with a new theoretical variogram fitted to the experimental.
The previous procedure was ment to estimate the variogram of the nonstationary
regionalized variable. If the variogram is available then the estimation of the value
at a point or block can be done in a similar way to kriging. The main difference is
that the drift has to be taken into account. The estimator is linear :
n

Z ‚àó (u) = ‚àë Œªi Z(ui )

(5.12)

i=1

The unbiasedness conditions in this case is:
"
n

E

#

‚àë ŒªiZ(ui) ‚àí Z(u) = 0

i=1

63

(5.13)

Using equations (5.1) and (5.2) this leads to:
n

S

S

i=1

s=0

s=0

S

"

‚àë Œªi ‚àë bs fs(ui) ‚àí ‚àë bs fs(u) = 0

From which:

(5.14)

#

n

‚àë bs ‚àë Œªi fs(ui) ‚àí fs(u) = 0

s=0

(5.15)

i=1

This equation should hold for any possible coefficients bs . This is fulfilled if:
n

‚àë Œªi fs(ui) ‚àí fs(u) = 0 for s = 0, . . . , S

(5.16)

i=1

As the estimation variance is:
n

n

n

j=1 i=1

i=1

œÉ2 (u) = Var[Z(u) ‚àí Z ‚àó (u)] = ‚àí ‚àë ‚àë Œª j Œªi Œ≥(ui ‚àí u j ) + 2 ‚àë Œªi Œ≥(ui ‚àí u) (5.17)
the best unbiased linear estimator is the one which minimizes œÉ2 (u) under the
constraints (5.16). Introducing the usual Lagrange multipliers this leads to a linear
equation system:
n

S

j=1

s=0

‚àë Œª j Œ≥(ui ‚àí u j ) + ‚àë ¬µs fs(ui) = Œ≥(ui ‚àí u) i = 1, . . . , n
n

‚àë Œªi fs(ui) = fs(u) s = 0, . . . , S

(5.18)

i=1

Universal kriging was the first geostatistical method dealing with non-stationary
random functions. The iterative estimation of the variogram is a time consuming
work, and there is no guarantee that the results will converge.

5.2

Intrinsic random functions of order k

Suppose that instead of a complete knowledge of the drift its funtional form is
given:
S

f (u) = ‚àë bs fs (u)
s=0

64

(5.19)

where coefficients bs are unknown.
The basic idea is to use increments of the sample values instead of the original values. These increments are formed in such a way that the unknown drift
coefficients b j do not influence them. Z 0 (Œò) is an increment if it is of the form:
n

Z 0 (Œò) = ‚àë Œ∏i Z(ui )

(5.20)

i=1

here Œò stands for the vector (Œ∏1 , . . . , Œ∏n ), where Œ∏i -s are real numbers, such that
the value of the increment is independent of the drift.
Increment Z(Œò) is independent of the unknown coefficients b j of the drift if
for all j

n

‚àë Œ∏i fs(ui) = 0

(5.21)

i=1

In this case using (5.1) one has:
n

0

Z (Œò) =

‚àë Œ∏iZ(ui) =

i=1
n

=
=
=
=

n

‚àë Œ∏i f (ui) + ‚àë Œ∏iY (ui) =

i=1
n

S

i=1

n

i=1
S

s=0
n

i=1
n

s=0
n

i=1

i=1

‚àë Œ∏i ‚àë bs fs(ui) + ‚àë Œ∏iY (ui) =
‚àë bs ‚àë Œ∏i fs(ui) + ‚àë Œ∏iY (ui) =

‚àë Œ∏iY (ui)

(5.22)

i=1

Thus in the case of the above drift the increment is the same as for the stationary residual. This enables the calculation of a generalized covariance function.
The simplest case is if the functions f (u) is a polynomial of order k. In this case
(5.21) can be written as:

n

‚àë Œ∏ixip = 0

i=1

65

(5.23)

for all p ‚â§ k in the 1 dimensional case.
n

‚àë Œ∏ixipyi = 0
q

(5.24)

i=1

for all p, q such that p + q ‚â§ k in the two dimensional case.
n

‚àë Œ∏ixipyi wri = 0
q

(5.25)

i=1

for all p, q, r such that p + q + r ‚â§ k in the three dimensional case.
In the case of k = 1, which means that there is an unknown linear trend, (5.23)
represents 2 equations for the 1 dimensional case, namely:
n

‚àë Œ∏i = 0

(5.26)

i=1
n

‚àë Œ∏i x i = 0

(5.27)

i=1

In two dimensions (5.24) represents 3 equations, the above two and:
n

‚àë Œ∏i y i = 0

(5.28)

i=1

In three dimensions (5.25) represents 4 equations, the above three and:
n

‚àë Œ∏ i wi = 0

(5.29)

i=1

If k = 2 (quadratic trend) d(d+1)
additional equations have to hold. For example
2
in the two dimensional case:

n

‚àë Œ∏ixi2 = 0

(5.30)

i=1
n

‚àë Œ∏iy2i = 0

(5.31)

i=1
n

‚àë Œ∏ixiyi = 0

i=1

66

(5.32)

In practice higher order polynomials are rarely used.
As Z 0 (Œò) is supposed to be stationary, its variance can be calculated with the
help of the generalized covariance function K(h)
n

n

Var[Z 0 (Œò)] = ‚àë ‚àë Œ∏i Œ∏ j K(ui ‚àí u j )

(5.33)

i=1 j=1

Here hi, j is the distance between points ui and u j . Matheron (1973) has shown
that valid generalized covariances for IRF-k s are of the form :
k

K(h) = CŒ¥(h) + ‚àë (‚àí1)r+1 ar h2r+1

(5.34)

r=0

Here Œ¥(h) = 1 if h = 0 and Œ¥(h) = 0 elsewhere. This term represents the nugget
effect.
Coefficients have to fulfil some additional conditions: C ‚â• 0 a0 ‚â• 0, a2 ‚â• 0
‚àö
and a1 ‚â• 10
3 a0 a2 . Using a set of admissible increments and calculating the corresponding variances, according to equation (5.33) the coefficients C and ar can
be estimated. This can be done in several ways, an overview is given in Kitanidis
(1983). In the present study the most traditional estimators using weighted regression techniques (Delfiner 1976), and the minimum norm estimator (Kitanidis
1983) was used.
Having identified the generalized covariance function, the minimum variance
estimator of the parameter at a given location can be calculated. For weights Œªi
n

n

n

n

i=1

i=1 j=1

i=1

Var[Z(u) ‚àí ‚àë Œªi Z(ui )] = ‚àë ‚àë Œªi Œª j K(hi, j ) ‚àí 2 ‚àë Œªi K(hi )

(5.35)

Here hi is the distance between points ui and u. The weights should be selected to
be insensitive to the drift:
n

‚àë Œªi f j (ui) = f j (u) for j = 1, . . . , m

(5.36)

i=1

Depending on the dimension of the space and the order k (5.36) means a different number of equations. If k = 1 then in the one dimensional case:
n

‚àë Œªi = 1

i=1

67

(5.37)

and

n

‚àë Œªixi = x

(5.38)

i=1

In two dimensions the above two equations and:
n

‚àë Œªiyi = y

(5.39)

i=1

In three dimensions the above three equations and:
n

‚àë Œªiwi = w

(5.40)

i=1

If k = 2 (quadratic trend) d(d+1)
additional equations have to hold. For example
2
in the two dimensional case:

n

‚àë Œªixi2 = x2

(5.41)

‚àë Œªiy2i = y2

(5.42)

‚àë Œªixiyi = xy

(5.43)

i=1
n

i=1
n

i=1

Weights Œªi can now be calculated with the help of the following linear equation
system:
n

S

j=1

s=0
n

‚àë Œª j K(hi, j ) + ‚àë ¬µs fs(ui) = K(hi) i = 1, . . . , n
‚àë Œªi fs(ui) = fs(u) s = 0, . . . , S

(5.44)

i=1

here the ¬µs -s are the Lagrange parameters. Depending on the order k and the
dimension of the space d these equations can be written with the help of the coordinates x, y, w.
As coefficients C, a0 , a1 , a2 , . . . of the generalized covariance function can be
calculated with the help of regression methods. IRF-k are well suited for automatic structure identification and automatic contouring.
68

A substantial difference between ordinary kriging and use of IRF-k lies in the
different degree of structural analysis. Variograms show several properties of the
parameter which cannot be recognized using IRF-k. Different methods (Cressie
- Hawkins estimators, trimmed means) can be used to obtain a useful variogram
but there is no analogue for IRF-k.
EXAMPLE 6.1 :

u1

u2

u

u3

u4

Figure 5.1: Data configuration for example 6.1
Suppose that using four points on a straight line the value at a fifth point is to
be estimated. The points are u1 = ‚àí3, u2 = ‚àí2, u3 = 1, u4 = 2. The point for
which the estimation is to be done is u = 0. Figure 5.1 shows the configuration.
Suppose that Z is a non stationary random variable of the form
Z(u) = u2 + u +Y (u)

(5.45)

where Y is intrinsic. Table 5.1 shows the data values.
Interpolation using IRF-0 IRF-1 and IRF-2 is investigated. The generalized
covariance function is assumed to be in each case K(h) = ‚àíh. (Note that different
constant multiples would yield the same results.)
The equation system in case of k = 0 is
0Œª1 ‚àí 1Œª2 ‚àí 4Œª3 ‚àí 5Œª4 + ¬µ1 = ‚àí3
‚àí1Œª1 + 0Œª2 ‚àí 3Œª3 ‚àí 4Œª4 + ¬µ1 = ‚àí2
‚àí4Œª1 ‚àí 3Œª2 + 0Œª3 ‚àí 1Œª4 + ¬µ1 = ‚àí1
‚àí5Œª1 ‚àí 4Œª2 ‚àí 1Œª3 + 0Œª4 + ¬µ1 = ‚àí2
Œª1 + Œª2 + Œª3 + Œª4 = 1
69

(5.46)

Point

Y

Z

u1

-1.0

7.0

u2

-0.5

2.5

u3

0.0

2.0

u4

1.0

7.0

Table 5.1: Values of Y and Z
From this one has Œª2 = 0.3333, Œª3 = 0.6667 Œª1 = Œª4 = 0 and ¬µ1 = 0. Thus
œÉ2 = 1.3333 and Z ‚àó (u) = 2.1667.
The equation system in case of k = 1 is
0Œª1 ‚àí 1Œª2 ‚àí 4Œª3 ‚àí 5Œª4 + ¬µ1 ‚àí 3¬µ2 = ‚àí3
‚àí1Œª1 + 0Œª2 ‚àí 3Œª3 ‚àí 4Œª4 + ¬µ1 ‚àí 2¬µ2 = ‚àí2
‚àí4Œª1 ‚àí 3Œª2 + 0Œª3 ‚àí 1Œª4 + ¬µ1 + 1¬µ2 = ‚àí1
‚àí5Œª1 ‚àí 4Œª2 ‚àí 1Œª3 + 0Œª4 + ¬µ1 + 2¬µ2 = ‚àí2
Œª1 + Œª2 + Œª3 + Œª4 = 1
‚àí3Œª1 ‚àí 2Œª2 + 1Œª3 + 2Œª4 = 0

(5.47)

For this case the solution is again Œª2 = 0.3333, Œª3 = 0.6667 Œª1 = Œª4 = 0 and
¬µ1 = ¬µ2 = 0. Thus œÉ2 = 1.3333 and Z ‚àó (u) = 2.1667. The explanation of this is
that the additional equation was already fulfilled by the solution of the previous
system.
The equation system in case of k = 2 is
0Œª1 ‚àí 1Œª2 ‚àí 4Œª3 ‚àí 5Œª4 + ¬µ1 ‚àí 3¬µ2 + 9¬µ3 = ‚àí3
‚àí1Œª1 + 0Œª2 ‚àí 3Œª3 ‚àí 4Œª4 + ¬µ1 ‚àí 2¬µ2 + 4¬µ3 = ‚àí2
‚àí4Œª1 ‚àí 3Œª2 + 0Œª3 ‚àí 1Œª4 + ¬µ1 + 1¬µ2 + 1¬µ3 = ‚àí1
‚àí5Œª1 ‚àí 4Œª2 ‚àí 1Œª3 + 0Œª4 + ¬µ1 + 2¬µ2 + 4¬µ3 = ‚àí2
70

Œª1 + Œª2 + Œª3 + Œª4 = 1
‚àí3Œª1 ‚àí 2Œª2 + 1Œª3 + 2Œª4 = 0
9Œª1 + 4Œª2 + 1Œª3 + 4Œª4 = 0

(5.48)

For this case the solution is different, namely: Œª1 = ‚àí0.25, Œª2 = 0.5833, Œª3 =
0.9167, Œª4 = ‚àí0.25 ¬µ1 = ‚àí0.75, ¬µ2 = 0.125 and ¬µ3 = 0.125. Thus œÉ2 = 1.5833
and Z ‚àó (u) = ‚àí0.2083. Note that the selection of k = 2 (the ‚Äúcorrect‚Äù choice)
yields a substantially different result. The difference between the drift u2 + u is
the smallest for this case. As the number of constraints increased the estimation
variance which is a constrained optimum also increased.

5.3

External-Drift-Kriging

External knowledge can be incorporated into the system with the External-Drift
Kriging (EDK) (Ahmed and de Marsily 1987). Here it is supposed that an additional variable Y (u) that is linearly related to the Z(u) exists. The assumption of
the constant expected value is thus replaced by:
E[Z(u) | Y (u)] = a + bY (u)

(5.49)

where a and b are unknown constants. The linear estimator (5.50) should be
unbiased for any a and b values. The linear estimator:
n

Z(u) = ‚àë Œªi Z(ui )

(5.50)

i=1

is considered. Minimizing the estimation variance under the above assumption
leads to the linear equation system:
I

‚àë Œª j Œ≥(ui ‚àí u j ) + ¬µ1 + ¬µ2Y (ui) = Œ≥(ui ‚àí u)

j=1

I

‚àë Œªj = 1

j=1

71

i = 1, . . . , I

I

‚àë Œª jY (u j ) = Y (u)

(5.51)

j=1

where ¬µ1 and ¬µ2 are Lagrange-multipliers. The Variogramm used in (5.51) is the
time invariant curve, as also used in OK. Note that the variable Y has to be known
at the location x, to perform an estimation. The estimator thus depends on the
additional variable Y (u).
EDK is an alternative for co-kriging. EDK can be taken if the secondary information Y (u) is available in a high spatial resolution, preferably regular grid.
Cokriging would require the estimation of covariogramms.

72

Chapter 6
Indicator Kriging
6.1

Indicator Variables

There are a great number of categorical natural variables, such as lithofacies, soil
types or other classes. It is often important to know the spatial extension of these
variables. One possibility to do this is to use indicator variables. The indicator
variable of a class C is defined as:

IC (u) =

Ô£±
Ô£¥
Ô£≤ 1

if u ‚àà C

Ô£¥
Ô£≥ 0

else

(6.1)

Even continuous variables can be transformed to indicators. In this case the
classes are defined with the exceedence of certain selected thresholds. The indicator variable IŒ± for a given threshold Œ± is defined as:

IŒ± (u) =

Ô£±
Ô£¥
Ô£≤ 1

if Z(u) ‚â§ Œ±

Ô£¥
Ô£≥ 0

if Z(u) > Œ±

(6.2)

The indicator variable I can also be regarded as the probability of u belonging
to class C or Z(u) being less than Œ±:
73

Figure 6.1: Indicator transformation of Z(u) for different Œ± values

IC (u) = P [u ‚àà C]

(6.3)

If indicator coding is performed for for a numerical variable Z(u)) using each
real value Œ± then each observation is transformed into a step function. In practice
a set of different Œ±k values k = 1, . . . , K is selected, and Z(u) is transformed into
the K dimensional vector (IŒ±1 (u), . . . , IŒ±K (u)).
The indicator variables IŒ± (u) are defined by dividing the measurement values
into classes.

6.2

Indicator Variograms

Similarly as in the case of arbitrary numerical variables one can also calculate
variograms using indicators. The experimental Indicator variogram Œ≥‚àóI (h) is calculated as: The variogram can be estimated with the help of the following formula
as in the case of the experimental variograms (Eq. 3.1):
Œ≥‚àó (h) =

1
‚àë (IŒ±(ui) ‚àí IŒ±(u j ))2
2N(h) ui ‚àíu
j =h

(6.4)

Here N(h) is the number of pairs of locations separated by the vector h.
The mean of an indicator variable p equals the probability of occurence of the
corresponding property. The variance of the variable is p(1 ‚àí p).

6.3

Indicator Kriging
n

IC‚àó (u) = ‚àë Œªi IC (ui ) .
i=1

This result can be interpreted as an estimator for probability of u ‚àà C.

74

(6.5)

The weights Œªi are calculated from the kriging equations as in the case of OK.
n

‚àë Œª j Œ≥I (ui ‚àí u j ) + ¬µ = Œ≥I (ui ‚àí u) i = 1, . . . , n

j=1

n

‚àë Œªj = 1

(6.6)

j=1

Indicator values can also be interpolated using SK or even EDK.
For numerical variables indicator kriging can be performed for a set of selected
levels Œ±k . Once this is done the numerical value of Z(u) can also be estimated.
For this purpose the class means ZÃÑk are introduced:
ZÃÑk =

‚àëni=1 Z(ui )(IŒ±k+1 (u) ‚àí IŒ±k (u))
‚àëni=1 Z(ui )(IŒ±k+1 (u) ‚àí IŒ±k (u))

(6.7)

The estimator Z ‚àó (u) for the unknown Z(u) can then be formulated as:
K

‚àó

Z (u) = IŒ±‚àó0 (u)Œ±0 +

‚àë (IŒ±‚àók+1 (u) ‚àí IŒ±‚àók (u))ZÃÑk ,

(6.8)

k=0

with
min z(ui ) = Œ±0 < Œ±1 < . . . < Œ±K = max z(ui )
Note that the indicator kriging approach has the advantages that the estimated
values remain in the prescribed range:
[min z(ui ), max z(ui )]
, and problems arising from highly skewed distributions are more or less overcome. On the other hand IK has disadvantages too. Even thought the observed
indicator values IŒ± (ui ) are monotonic as a function of the threshold value Œ±, this
is not always true for the kriged IŒ±‚àó (u)-s. The reason for this is that the kriging
weights can also become negative. In this case first the IŒ±‚àó (u)-s have to be altered
in order to make them monotonic in Œ±. Another problem is the discretization of
the variables. The indicator coding does not distinguish between Z(ui ) 6= Z(u j )
if they both belong to the same indicator class: Œ±k < Z(ui ), Z(u j ) < Œ±k+1 which
means a loss of information and a loss of accuracy.
75

6.4

Applications

Indicators can very well be used for the mapping of categorical variables, such
as lithofacies, soil types etc. The indicator transformation is also very useful for
variable with highly skewed distributions.

6.4.1

Interpolation of a categorical variable

Consider the problem of interpolating a soil map. Observations of the soil type
are available at selected locations ui .

6.4.2

Detection limit problem

Pollutants with very low concentrations are difficult to interpolate. The main problem here is that there are measurements which are below the detection limit. If
one tries to estimate the mean value of these parameters for unobserved locations
assumptions of the values being below the detection limits have to be made. There
are several possibilities:
1. To consider these values as zero. This is a very optimistic assumption.
2. Not to consider these data. This assumption leads to an overestimation as
all small values are removed.
3. To consider all these values as a selected value between zero and the detection limit. This assumption is arbitrary and changes the uncertain data to
exact values.
Instead of the above mentioned cases one can estimate the exceedence probabilities using indicator variables and indicator kriging.
EXAMPLE 6.1 :

76

A work on interpolation of the pollution of groundwater in Baden-WuÃàrtemberg, done in 1995, had to face the following problems dealing with the pollutant
Atrazine:
‚Ä¢ The concentrations of Atrazine were of same quantity as the detection limits, so an concrete consideration of values below the detection limits would
have strong influence on the interpolation, the same problem occurs, if the
data below the detection limits would have been removed (s.a.).
‚Ä¢ Different measurements had very different detection limits, the biggest limits being multiples of the smaller ones and of same quantity as the values of
most measurement points.
To deal with this data, they were coded with three indicator variables:
Œ±1 = 0, 01¬µg/l

Œ±2 = 0, 02¬µg/l

Œ±3 = 0, 05¬µg/l.

The positive effect of the indicator coding was, that only measurements with
detection limits bigger than the indicator limit had to be removed from the data-set
in case of being below the detection limit. In the case of a detection limit smaller
than the indicator all measurements could be used: all measurements below the
detection limit had value IŒ± = 1 then. In this case not all low data are removed
and the problem of overestimation is reduced.
In that work the data-set contained measurements of 2540 points, after removal
of not usable points the data-sets of the three indicator contained:
I3 :

2437 points

I2 :

1772 points

I1 :

1449 points

On this three data-sets kriging was made with different methods as OK, BayesMarkov-Kriging and SU. The necessary variograms were calculated for each indicator variable separately.
The figure 6.2 shows the SUK of Desethylatrazine which is a product of decomposition of herbicide Atrazine forŒ± = 0, 05¬µg/l.

77

Figure 6.2: SUK of Desethylatrazine in groundwater in Baden-WuÃàrttemberg

78

Chapter 7
Kriging with arbitrary additional
information
The previously described procedures can consider additional information, but only
in a numerical form, assuming a linear relationship. A non-linear relationship with
the additional variable or a close connection to a censored variable is also possible.
An estimation method to cope with these problems is the Markov-Bayes Kriging
(MBK) described in Journel and Zhu (1990). Another possibility is to use a simple
updating (SU) procedure.

7.1

Markov-Bayes-Kriging

Formally MBK uses the assumption that additional information can be taken into
account for the assessment of prior distributions at selected locations.
UŒ± (u) = P[Z(u) ‚â§ Œ±|additional information]

(7.1)

If this UŒ± is different from the distribution F(Œ±) then the additional information
is useful for the estimation of Z(u). The estimation is then performed by using
the global prior information F(Œ±), the local prior UŒ± (uk ) and the indicator coded
observations Z(ui ). For MBK it has to be assumed that UŒ± (uk ) is available at
79

considerably more locations as direct observations of Z. This way one hopes to
improve the estimation of Z by using the additional information coded in U. In
several applications the additional information is available for all points in the
investigated domain.
The indicator values IŒ± are estimated using a simple cokriging approach:
n

K

IŒ±‚àó (u) = Œª0 F(Œ±) + ‚àë Œªi IŒ± (ui ) + ‚àë ŒΩkUŒ± (uk )
i=1

(7.2)

k=1

In fact MBU is a ‚Äùmixture‚Äù of three possible approaches:
1. assigning the same mean to the whole domain (Œª0 )
2. spatial interpolation (Œªi , i = 1, . . . , n)
3. assigning values from the additional information only. (ŒΩk , k = 1, . . . , K).
The spatial dependence, the configuration of the observation points and the usefulness of the additional information are influencing the role of the above factors.
For the calculation of the weights Œªi and ŒΩ one needs the covariance function
of IŒ± and UŒ± and their cross-covariance function. The formulation of the equations
by using variograms is also possible, but in this case the covariance based form is
simpler.
According to Journel and Zhu (1990) the covariance function of U and the
cross covariance function of I and U can be expressed with the help of the covariance function of I.

CU (h) =

CIU (h) = B(Œ±)CI (h)
Ô£±
Ô£¥
Ô£≤ B2 (Œ±)CI (h)
if h > 0

(7.3)
(7.4)

Ô£¥
Ô£≥ B2 (Œ±) +V 2 (Œ±) for h = 0
f
Here the quantities B(Œ±),Vc (Œ±) and V f (Œ±) reflect the usefulness of the additional information. They are formally defined as
B(Œ±) = E[UŒ± (x,t)|IŒ± (x,t) = 1] ‚àí E[UŒ± (x,t)|IŒ± (x,t) = 0]
80

(7.5)

and
V f2 (Œ±) = Ft (Œ±, x)Var[UŒ± (x,t)|IŒ± (x,t) = 1] + (1 ‚àí Ft (Œ±, x))Var[UŒ± (x,t)|IŒ± (x,t) = 0]
(7.6)
The weights Œªi and ŒΩk are calculated by using simple cokriging with the single
additional point x:
n

K

i=1

k=1

n

K

‚àë ŒªiCI (xi ‚àí x j ) + ‚àë ŒΩkCIU (x j ‚àí xk0 ) = CI (x j ‚àí x)
for

j = 1, . . . , n

‚àë ŒªiCIU (xi ‚àí xl0 ) + ‚àë ŒΩkCU (xl0 ‚àí xk0 ) = CIU (xl0 ‚àí x)

i=1

(7.7)

k=1

One can see from the equation system above that the updating of the prior
functions depends on CU and CIU . The bigger the value of V f2 (Œ±) the higher is
the importance of the hard information. This is reasonable as V f2 (Œ±) reflects the
quality of the additional information.
The additional information Y (x) available at each location xk0 is used to define
the variable UŒ± as
UŒ± (x,t) =

1
IŒ± (x j ,t)
N(x) Y (x0 ‚àë
)‚âàY (x)

(7.8)

k

N(x) is here the number of observation points which have similar Y values (Y (xk0 ) ‚âà
Y (x j )). In practice this is done the way that classes are defined for the variable
Y (x), and the mean indicator values over the classes are assigned to the unobserved locations as prior information. Note that Y (x) can be any classification,
both numeric values can be grouped into classes or categorical variables, such as
land use. The quantities B(Œ±) and V f (Œ±) can easily be calculated once UŒ± has
been defined.

7.2

Simple Updating (SU)

Consider the situation where Z(x) is complemented by a secondary variable L(x)
available at each point in the domain. This variable is discrete, and related to Z(x)
81

through a conditional expectation:
E[Z(x) | L(x) = l] = ml

(7.9)

Var[Z(x) | L(x) = l] = œÉ2l

(7.10)

and a conditional variance:

In this case the first estimation of Z(x) is that based on L(x)
Z 0 (x) = mL(x) + ŒµL(x) (x)

(7.11)

with ŒµL(x) (x) being a random error with 0 expectation and variance œÉ2L(x) . Using
Z 0 (x) for the estimation of Z(x) combined with the observations one has:
n

Z ‚àó (x) = Œª0 Z 0 (x) + ‚àë Œªi Z(xi )

(7.12)

i=1

The estimation variance for this estimator is:
n

n

Var[Z(x) ‚àí Z ‚àó (x)] = ‚àí ‚àë ‚àë Œª j Œªi Œ≥(xi ‚àí x j )+
j=1 i=1

n

+2 ‚àë Œªi (1 ‚àí Œª0 )Œ≥(xi ‚àí x) + Œª20 E[Œµ(x)2 ]

(7.13)

i=1

Minimizing this estimation variance with respect to the unbiasedness condition leads to the equation system:
n

‚àë Œª j Œ≥(xi ‚àí x j ) + ¬µ = (1 ‚àí Œª0)Œ≥(xi ‚àí x) i = 1, . . . , n

j=1
n

‚àë Œª j Œ≥(x ‚àí x j ) + ¬µ = Œª0œÉ2l

j=1

n

‚àë Œªj = 1

(7.14)

j=0

This is a linear equation system for the unknown weights Œªi , and the solution
yields the estimator Z ‚àó (x). The additional variable L(x) can be any discrete variable, for example soil type, landuse or geological code.
82

In practice we suppose that additional information in the form of a discrete
index (1, . . . , M) L(x) is available for every location in the field. For each class l
the mean ant the variance can be calculated as
‚àëni=1 Z(xi )1{L(xi ) = l}
ml =
‚àëni=1 1{L(xi ) = l}

(7.15)

‚àëni=1 (Z(xi ) ‚àí ml )2 1{L(xi ) = l}
(‚àëni=1 1{L(xi ) = l}) ‚àí 1

(7.16)

s2l =
EXAMPLE 7.1 :

A work on interpolation of the pollution of groundwater in Baden-WuÃàrttemberg, done in 1995, intended to optimize the interpolation by use of additional
information, available for the whole area of interest. Available information was
a classification of landuse in 16 classes, and a classification of the groundwater
geology in 19 classes.
The pH-value was interpolated with both classifications using MBK. For this
purpose the classifications had to be revised by combining smaller classes, to
achieve classes with at least 18 points of measurement. This was necessary to
get statistical values of this classes of sufficient quality. This grouping was done
manually and reduced the number of classes to 13 classes of landuse and 15 of
geology.
The data were coded to 9 indicator variables which correlations were calculated. The distribution of data of the classes of landuse and geology were calculated and also their correlations and the cross-correlations to the indicator functions. With these prior informations a BMK was calculated. This contains a big
amount of calculations, especially 9 variograms for the indicator variables.

EXAMPLE 7.2 :
83

The same data have been optimised with the SU-algorithm in a second work
on the pollution of groundwater in Baden-WuÃàrttemberg in 1996. Because SU
affords a significant less amount of calculation and especially only one variogram
has to be fitted, it has been possible to spend more work on the optimisation of the
classification.
For this purpose a combined classification of landuse and geology has been
made, containing 304 classes. These had to be combined to classes with at least 18
points of measurement. For that work algorithms had been designed, combining
classes under aspects of statistical similarities in the parameter of interest and
under the aspect of similarities in their character (combining classes with foresttype landuse to each other etc.). This lead to classifications of a quantity of fifty
to sixty classes for a data-set containing 2540 points of measurement.
These classifications were used for a SU-algorithm. In table 7.1 the MeanSquare-Error (MSE) of cross-validations of some of that calculations are presented (for two different groupings of the classes), compared to results of example
7.1 and of an OK of the same data-set. The ranking of interpolation of this examples are not general. Calculations on other data-sets (e.x. NO3 ) presented different
rankings, at least SU was the most powerfull algorithm for all seven data-sets in
that investigation.
Table 7.1: Cross-Validation for pH-value

algorithm

OK

SU(Grouping 1)

SU(Grouping 2)

MBK(Geology)

MBK(Landuse)

MSE

0,089

0,0821

0,0822

0,086

0,097

EXAMPLE 7.3 :
Another parameter investigated in the work on the pollution of groundwater
in Baden-WuÃàrttemberg was Nitrate. The methods have been the same as in the
84

previous examples. To give some impression about the differences in interpolation
some results are presented in the following.
The measurements of Nitrate have been interpolated with different methods,
the results of OK, MBK and SU are presented in the figures 7.3, 7.4 and 7.5. To
get an impression about the data-base figure 7.1 presents a map of the points of
measurement used for the interpolations. The additional informations used for
the interpolations are the landuse for the MBK and a combination of landuse (see
figure 7.1) and geology (see figure 7.2) for the SU. Figure 7.6 shows another SUK
(Simple Updating Kriging) of Nitrate in groundwater in Baden-WuÃàrttemberg.
Nitrate is one of the seldom examples, where the OK had better results than
the MBK when comparing the Mean-Error of the cross validation. Nevertheless
the MBK seems to be more trusting because OK gives an overestimation in the
surroundings of extreme big values and is not capable to work out spatial structures caused by the character of the regions like the Black Forest. SU is here
assumed to be the best method, because it has the lowest error in cross validation
combined with clearly outworked structures in the interpolation. The results of
cross validation are shown in table 7.2.
Table 7.2: Cross-Validation for Nitrate [(mg/l)2 ]
method

OK

SU(Grouping 3)

BMU(landuse)

MSE

374

337

385

85

Figure 7.1: Points of groundwater-measurement and landuse in Baden-WuÃàrttemberg

86

Figure 7.2: Aquifers in Baden-WuÃàrttemberg as additional hydrogeological information to SU

87

Figure 7.3: OK of Nitrate in groundwater in Baden-WuÃàrttemberg

88

Figure 7.4: MBK of Nitrate in groundwater in Baden-WuÃàrttemberg

89

Figure 7.5: SU of Nitrate in groundwater in Baden-WuÃàrttemberg

90

Figure 7.6: SUK of Nitrate in groundwater in Baden-WuÃàrttemberg

91

Chapter 8
Time dependent variables
Geostatistical methods were originally thought for mining and geological problems, where at a certain location only one measurement (borehole) can be made,
and a single realization is observed. However in many other applications the same
location can be used for several measurements. For example groundwater quality
or quantity parameters or precipitation is often measured regularly in time. The
question is how to model and how to use this in geostatistical evaluations. Unfortunately because of the interest of geostatisticians in single realizations there is
not much in the literature about this problem.
A possible method to include time is extending the intrinsic hypothesis to the
time dimension. This means that measurement locations consist of two parts: a
spatial (1,2 or 3 dimensions), and a temporal. This approach is more or less reasonable for timewise continuous variables like groundwater quality parameters. It
is unreasonable for precipitation (one cannot use the precipitation of June 1 and
June 30 to calculate the precipitation for June 15) and other event-based parameters.
Another possible extension is to use the data corresponding to the same time as
a realization, and to suppose that the different realisations correspond to the same
or at least to a similar process. (The notion of similar process will be explained
later). This second method does not exclude the first, ‚Äútime cuts‚Äù of an intrinsic
92

space-time process are also intrinsic in space, and the spatial variograms are the
same.

8.1

Space ‚Äî time intrinsic variables

The random function Z(u,t) is space time intrinsic if:
E[Z(u,t)] = m

(8.1)

The space time variogram:
1
Œ≥(h, ‚àÜt) = Var[Z(u + h,t + ‚àÜt) ‚àí Z(u,t)]
2
is independent of the location u and the time t.

(8.2)

For example slowly changing groundwater quality parameters often show such
a space time intrinsic behavior.
A serious problem in calculating space time variograms is that there is no common distance measure. Spatial distances can be calculated, and time differences,
too. It is important to find the spatial equivalent of a time difference. This can
be done by calculating the experimental variograms for time and for the spatial
stucture separately.
Œ≥‚àóT (‚àÜt) =

1
‚àë (Z(ui,ti) ‚àí Z(u j ,t j ))2
2NT (h) (i, j)‚ààR
(h)

(8.3)

T

Here
RT (h) = {(i, j); ‚àÜt ‚àí Œµ ‚â§ |ti ‚àí t j | ‚â§ ‚àÜt + Œµ and (ui = u j )}

(8.4)

and NT (h) = the number of elements in RT (h). For the spatial structure:
Œ≥‚àóS (h) =

1
‚àë (Z(ui,ti) ‚àí Z(u j ,t j ))2
2NS (h) (i, j)‚ààR
(h)

(8.5)

S

where
RS (h) = {(i, j); h ‚àí Œµ ‚â§ |ui ‚àí u j | ‚â§ h + Œµ and |ti ‚àí t j | ‚â§ Œ¥}
and NS (h) = the number of elements in RS (h) There two possibilities:
93

(8.6)

1. The two kinds of experimental variograms are similar, have the same nugget
effect and the same sill. This means that a geometric anisotropy can be considered between the time and spatial scale. In this case a linear transformation of the time scale leads to a space‚Äîtime isotropic model. The new
‚Äúlength‚Äù of a vector (h, ‚àÜt) is defined as:
q
|(h, ‚àÜt)| = |h|2 + kt |‚àÜt|2

(8.7)

2. The two kinds of experimental variograms are different, having different
shape and/or sill etc. In this case a zonal anisotropy type of modelling can
be used. Namely the space‚Äîtime variogram Œ≥ST (h, ‚àÜt) can be written in the
form:
Œ≥ST (h, ‚àÜt) = Œ≥S (h) + Œ≥T (‚àÜt)

(8.8)

In both cases space‚Äîtime kriging and space time simulation can be done similarly
as in the spatial case.

8.2

Spatially intrinsic variables with time independent variograms

The random function Z(u,t) is spatially time intrinsic with time independent variograms if:
E[Z(u,t)] = m

(8.9)

1
Œ≥(h) = Var[Z(u + h,t + ‚àÜt) ‚àí Z(u,t)]
2

(8.10)

The spatial variogram :

is independent of the location u and the time t if ‚àÜt ‚â§ Œ¥.

94

8.3

Spatially intrinsic variables with time dependent
variograms

The random function Z(u,t) is spatially time intrinsic with time dependent similar
variograms if:
E[Z(u,t)] = m(t)

(8.11)

and the spatial variogram at the given time t:
1
Œ≥(h,t) = k(t) Var[Z(u + h,t + ‚àÜt) ‚àí Z(u,t)]
2

(8.12)

is independent of the location u if ‚àÜt ‚â§ Œ¥ and k(t) is a time dependent function.
There are several possible choices for the function k(t). For example
‚Ä¢ Mean proportional variograms :
k(t) = m(t)2

(8.13)

This means that Z(u,t)
m(t) is spatially intrinsic with a time independent variogram.
‚Ä¢ Variance proportional variograms :
k(t) = Var[Z(u,t)] with fixed t

(8.14)

This means that the correlation structure is preserved over the time.

8.4

Time series interpreted as different realisations

In the case of fast changing or event-based parameters, time series can be used
for a far-reaching analysis of the spatial correlation structure of the obtained data.
This requires that we can assume the observed process as similar during time, but
similarity is only necessary in the correlation of the events in spatial distributed

95

points of measurements. If this assumption is possible, can be detected by calculating the correlation coefficient œÅ for time series of pairs of the locations of
measurement ui and u j :
C[Z(ui ,t), Z(u j ,t)]
œÅi j = p
Var[Z(ui ,t)] ¬∑Var[Z(u j ,t)]

(8.15)

with temporal covariance C:
C[Z(ui ,t), Z(u j ,t)] = E[{Z(ui ,t) ‚àí E[Z(ui ,t)]}{Z(u j ,t) ‚àí E[Z(u j ,t)]}]

(8.16)

The correlation coefficient is the standardized temporal covariance, the value
1 shows a strict positive linear relation between the two time-series, a 0 indicates
two time-series without any (linear) relation, negative values indicate negative
linear relations. If calculated for a number of pairs, the correlation coefficient
denoted as a function of the distance between those pairs should show a similar
figure then a spatial covariance function (c. chapter 2.3).
If the assumption of similarity in time is met, the correlation coefficients can
be used mainly in two ways:
1. The covariances according to the correlation coefficients are a quite better
base for calculating a spatial variogram than the measured values for a single time. For this they can be used directly as a covariance cloud to estimate
a spatial covariance, similar to a variogram cloud used for the estimation of
a variogram, and then used for kriging calculation. For this purpose it is easily possible to express the Kriging conditions in terms of correlation instead
of variogram (c. chapter 4.1).
2. The information contained in the spatial correlation structure can be used for
a further optimisation of a theoretical correlation function. For this purpose
spatial transformations can be calculated on this base.
EXAMPLE 8.1 :
96

For example precipitation is known to depend on the height and on the slope
of the terrain observed. In actual research an optimisation of the spatial correlation structure is aimed by a transformation in a high dimensional space. In this
transformed space height and the slope are additional dimensions and the transformation includes several scaling parameters which are fitted to a theoretical spatial
correlation function. The calculation fits seven spatial scaling parameters plus
two free parameters for the theoretical correlation function which is quite a big
amount (which can only be done numerically) but the results show a significant
lesser discrepancy between theoretical and experimentally observed correlation.

97

Chapter 9
Simulation
Kriging as most interpolation techniques delivers idealized smooth results. This
is because the minimum estimation variance as optimality criterion necessarily
yields less variable estimators. If an experimental variogram is calculated from
the kriged values, then it is different from the one obtained from measurements.
Variances corresponding to different distances are usually much smaller for the
kriged values. In many cases the variability of the regionalized variable plays
a central role for decisions (for example reliability aspects). Therefore a procedure to obtain interpolation reproducing the variogram of the original variable is
needed. Simulation is the method for doing this.
Simulation should reproduce the variability of the regionalized variable. The
simulated values should have the same mean, variance and variogram as the measured ones. Quite often the histogram of the measured values should also be
reproduced. Simulation should deliver one possible reality.
Simulation is very useful in the case of parameters which are themselves not
a final product of the analysis. For example in groundwater modeling hydraulic
conductivity is an essential parameter, but it is an input of a subsequent model.
The pupose of modeling is to deliver accurate head values, which are dependent
on the hydraulic conductivities. Expected head values are not the same as the head
values calculated with expected conductivities.
98

9.1

Basic definitions

Simulation methods form two different groups:
1. methods generating realizations with given spatial variablity and distribution
2. methods gegenerating realizations with given spatial variablity under consideration of additional information
In both groups depending whether the simulated realizations honor the observations or not two cases are distinguished:
1. unconditional simulations: delivering realizations with prescribed variablity
without honoring the observation data
2. conditional simulations: delivering realizations with prescribed variablity
honoring the observation data
There are at least four different ways simulating realizations of Z(u) under the
above constraints:
‚Ä¢ Monte Carlo simulations
‚Ä¢ turning band simulations
‚Ä¢ sequential simulations
‚Ä¢ simulated annealing

9.2

Monte Carlo Simulations

Monte Carlo simulations generate realizations multidimensional (generally normal) distributions. The simulation uses Y j independent standard normally (N(0,1))

99

distributed random variables Y j . Let the variables Zi be linear combinations of the
Y j -s:
N

Zi = ‚àë ci jY j
j=1

The covariance of Zi and Zk is:
N

N

N

N

j=1

l=1

j=1

l=1

Cov(Zi , Zk ) = Cov( ‚àë ci jY j , ‚àë cklYl ) = E( ‚àë ci jY j ‚àë cklYl ) =
N

N

j=1

j=1

= E( ‚àë ci j ck jY jY j ) = ‚àë ci j ck j

(9.1)

Here we used the independence of the Y j -s.
In this case the covariance matrix Œì is decomposed as the product of a matrix
and its transpose:
Œì = CCT

(9.2)

This latter matrix is then used to transform a vector of independent N(0, 1) random variables to the required multidimensional distribution. The disadvantage of
this method is that the dimension of the covariance matrix equals the number of
points for which simulated values should be calculated, thus the computational
requirements of the method increase drastically with the number of points. The
‚Äôsquare root‚Äô of the covariance matrix (9.2) can be found using the Jacobi method.
An alternative is to use an LR decomposition of the covariance matrix, which can
be achieved using a Cholevski decomposition.

9.3

Turning Band Simulation

In turning band simulations sets of one dimensional simulations are merged to a
two (or three) dimensional one. One dimensional simulations are performed for
different possible directions ‚Äúturning‚Äù around a center point. Depending on the
variogram different covariance structures have to be used for the one dimensional
simulations. The advantage of the method is that it is nearly independent from the
100

number of points. A disadvantage is that the one dimensional covariance structure
corresponding to the variogram has to be calculated (or given analytically).
The general idea of turning band simulations is given on the next few pages,
without full computational details.

9.3.1

Unconditional simulation

The basic idea of turning band simulations is to use a set of one dimensional simulations to construct the multidimensional one. Projecting a point in the 2 or 3
dimensional space onto these lines, and taking the sum of the values corresponding to the projected points, yields the simulated value.
Suppose that for a set of lines l = 1, . . . , L, all going through the origin of the
coordinate system, random functions with zero mean and C1 (r) covariance functions are simulated independently. Let Zl (u) for l = 1, . . . , L be these functions.
Then for a point u the random function Z(u) can be defined as
1 L
Z(u) = ‚àö ‚àë Zl (hu, vl i)
L l=1

(9.3)

here h., .i denotes the scalar product of the vectors, and vl is the unit vector on line
l. Figure 9.1 explains the definition of Z(u) in the two dimensional case.
Using the fact that E[Zi (r)] = 0 the covariance function of the above defined
random Z(u) is:
C(u1 , u2 ) =

1 L L
‚àë ‚àë Zl (hu1, vl i)Zl (hu2, vk i)
L l=1
k=1

(9.4)

As Zl and Zk are independent if l 6= k the above sum can also be written as:
C(u1 , u2 ) =

1 L
‚àë Zl (hu1, vl i)Zl (hu2, vl i)
L l=1

=

1 L
‚àë C1(|hu1, vl i ‚àí hu2, vl i|)
L l=1

1 L
=
‚àë C1(|hu1 ‚àí u2, vl i|)
L l=1
101

(9.5)

u

s
A
A
A

B
B
B
B


line l



A 
A


B
A


B
A


B

A

B
A

B

A

*


*A
B





vl
A

B
A


B
0



B




B



hu, vl i


B



B



A

B

Figure 9.1: Turning bands lines and the projection
This equation shows that Z(u) is also stationary. If the unit vectors vl are uniformly distributed on unit sphere or on the unit circle, then taking the limit of the
above expression as L ‚Üí ‚àû
C(h) =

1
S

Z
|v|=1

C1 (|hh, vi|)

(9.6)

here S is the surface of the unitsphere (4œÄ) or the length of the perimeter of the unit
circle (2œÄ) depending on the dimension. As the covariance is isotropic the value
of C(r) for a given distance r can be calculated with the help of any vector h of
length r. The two and the three dimensional cases have to be handled differently.

102

Two dimensional simulation
Selecting h = (r, 0) and introducing the polar coordinates (9.6) can be rewritten in
the form:
1
C(r) =
2œÄ

Z 2œÄ
0

2
C1 (r cos œï) dœï =
œÄ

Z œÄ
2

0

C1 (r cos œï) dœï

(9.7)

Substituting œÑ = r cos œï
2
C(r) =
œÄ

Z r

C (œÑ)
‚àö 1
dœÑ
0
r 2 ‚àí œÑ2

(9.8)

The integral equation (9.8) has to be solved for different possible covariance functions ‚Äî corresponding to variograms with a sill.
Three dimensional simulation
Selecting h = (r, 0, 0) and introducing the spherical coordinates (9.6) can be rewritten in the form:

1 2œÄ œÄ
C(r) =
C1 (r cos œï) dœï dŒ∏
4œÄ 0 0
Introducing œÑ = r cos œï after some calculations one finally has:
Z

Z

1
C(r) =
r

(9.9)

Z r
0

C1 (œÑ) dœÑ

(9.10)

Note that (9.10) is much simpler than its two dimensional equivalent (9.8). It can
even be rewritten as

d
[œÑC(œÑ)]
(9.11)
dœÑ
This equation makes it possible to derive for each theoretical model the correC1 (œÑ) =

sponding one dimensional covariance function. Then using one dimensional simulation methods (many of them can be found in the time series literature) Zl functions are generated, and using (9.3) Z(u) is constructed.

103

Simulation of complex models
The solution of the equations relating the three dimensional covariance function
to the one dimensional is quite difficult. For complex models it is much simpler
to use the solution for the particular models (spherical, exponential etc.) and
to simulate random functions for these models. The simulation for the complex
model can then be constructed with the help of (3.14) and (3.15).
The same idea can be used to simulate random functions with zonal anisotropy.
Turning band simulations generate realisations of multidimensional normal distributions. The reason for this is that the random function is the sum of independent
random variables, and by the central limit theorem these sums converge to the
normal distribution. In order to obtain simulations for non normal distributions
transformations have to be done. The transformation which transforms the required distribution to the normal has to be found. Then using this transformation
variograms of the transformed variable have to be calculated. Simulation is then
performed for the transformed variable, and finally the results are transformed
back to the original scale. This procedure often helps but there is no guarantee.
Sometimes even the conditioning transforms the distribution to the required one.

9.3.2

Conditional simulation

The measurement data are not really used in unconditional simulation. It is only
through the variogram they influence simulation results. The knowledge of the
value of a selected parameter at a given point restricts the possible values in a
neighbourhood. Those realizations are specially interesting for which at the measurement points the simulated values equal the measurement values. Unconditional simulations are conditioned with the help of a simple transformation :
ZC (u) = Z ‚àó (u) + (ZS (u) ‚àí ZS‚àó (u))
here
ZS (u) is the simulated value at point u
104

(9.12)

ZS‚àó (u) is the kriging estimator of ZS based on the simulated values at the measurement points
ZC (u) is the conditionally simulated value at u
Z ‚àó (u) is the kriging estimator of Z based on the measurement data
Because of the exactness property of kriging, for measurement points ui Z ‚àó (ui ) =
Z(ui ) and ZS‚àó (ui ) = ZS (ui ). Thus by definition ZC (ui ) = Z(ui ). This means that the
above modification of the unconditional simulation reproduces the measurement
values. It can also be shown, that (9.12) does not influence the variability, ZC (u)
and ZS (u) have the same variogram.

9.4

Sequential Simulation

Another possibility to obtain simulated random fields is the sequential simulation.
The basic idea of this method is, that conditional distributions of the observed
variable can be assessed and used for the simulation of subsequent points.

9.5

Simulation using Markov Chains

Another possibility to simulate realizations of a random field is simulated annealing. The basic idea of simulated annealing is to generate realizations of a random
field for which the distributional assumptions are not convenient to sample them
directly. For this purpose a Markov-chain is defined which has the prescribed
limit distribution. The theoretical basis for this is the Hastings algorithm (Hastings 1970).

9.5.1

The Hastings Algorithm

The essential part of this is the Hastings algorithm: A given probability distribution œÄi on the finite ‚Ñ¶ can be simulated using a Markov chain. For this purpose

105

take an arbitrary transition matrix
Q = (qi j )
of an irreducible Markov chain. Define the matrix P as:
pi j = Œ±i j qi j

(9.13)

pii = 1 ‚àí ‚àë pi j

(9.14)

and
j6=i

Let Œ±i j be given by:
Œ±i j =

si j

œÄq

1 + œÄ ij qijij

(9.15)

where the si j -s have to be symmetric:
si j = s ji
and

œÄi qi j
œÄ j q ji
For this Markov chain one can see that the limiting distribution of it is œÄ. In the
0 < si j < 1 +

Metropolis algorithm the Q matrix is chosen symmetric and:


œÄj
Œ±i j = min 1,
œÄi

(9.16)

Note that in all previous equations the probabilities œÄi had to be known up to a
constant multiplier as only the ratios œÄœÄij were required.
The method can also be applied in the continuous case (see Chib and Greenberg 1995).

9.5.2

Simulated annealing

In simulated annealing the probability distribution œÄ is defined with the help of an
objective function O depending on the state i:
œÄi = K exp(‚àíO(i))
106

(9.17)

In simulated annealing in order to find the limiting distribution on the realizations
corresponding to the minima of O the temperature T is introduced. This means
the Hastings algorithm is performed for the limiting distribution:
œÄ(T ) = K(T ) exp(‚àí

O(i)
)
T

(9.18)

If the temperature T is decreased to 0 then for each state i with no global minimum
the probability œÄi (T ) ‚Üí 0. Constraints on the rate of decrease of the temperature
T to ensure a convergence to the uniform distribution on the set of global minima
can be found in Geman and Geman (1984).
The simulation is performed on a predefined grid.
The algorithm can be described as follows:
1. Assign every grid cell corresponding to a measurement location the correct
(measured) value.
2. Assign the remaining cells randomly values from the overall distribution.
3. Select an ‚Äùenergy function‚Äù O, which measures the difference between the
statistical properties of the actual image and the prescribed properties.
4. Select a starting temperature t, and a number of swaps NS to be tried before decreasing the temperature. Select a rate in which the temperature
decreases.
5. Select two cells at random which do not correspond to measurement locations. Swap the values and calculate the value of the energy function On
and compare it with the value for the unchanged case Oo . If On < Oo then
keep the swap. Else calculate the probability of acceptance pa :


On ‚àí Oo
pa = exp ‚àí
t

(9.19)

Accept the swap with probability pa and undo it with probability 1 ‚àí pa .
6. Repeat the previous step NS times.
107

7. Reduce the temperature slightly, according the rate of 4. Repeat steps 5-6.
8. Repeat the previous step until the energy function value O is close to zero.
The most important part of this procedure is the selection of the energy function O.
Here both general assumptions - like the reproduction of a variogram, and other
properties like local distributions can be taken into account. A possible form for a
variogram dependent objective function is:
OŒ≥ = ‚àë [Œ≥r (hi ) ‚àí Œ≥m (hi )]2

(9.20)

hi

where Œ≥r is the variogram value corresponding to the generated image and Œ≥m is
the variogram to be achieved (model value). The function Œ≥m can in this case
both be a theoretical variogram or even an experimental value. The advantage
here is that difficult cases, such as zonal anisotropy can be simulated with this
approach. Frequently the variogram values corresponding to small distances play
a much more important role, thus the variogram objective function is formulated
with relative deviations as:
OŒ≥ = ‚àë
hi




Œ≥r (hi ) ‚àí Œ≥m (hi ) 2
Œ≥m (hi )

(9.21)

The objective function for the neighbouring points can be formulated either directly or from a training image.
ON = ‚àë ‚àë | f r ‚àí f m |

(9.22)

xi N

The final energy function is then formulated as a linear combination of the variogram and the neighbourhood objective function:
O = Œ±Œ≥ OŒ≥ + Œ±N ON
with Œ±Œ≥ and Œ±N being positive weights.

108

(9.23)

Further properties can also be formulated as objective functions. However it
is very important that the objective function has a form which allows a fast update
of the energy function in case of a swap.
The initial temperature should be selected in a way that quite a great number
of non-improving swaps are performed at the beginning of the simulation. This
way the independence of the final result from the initial picture is guaranteed.
The number of swaps to be tried at a given temperature should be high enough, in
general values around the number of points in the simulation grid are recomended.
The advantages of the simulated annealing algorithm include:
1. Arbitrary marginal distributions can be simulated.
2. The objective function can include different information, and can be formulated in a flexible way.
3. The space containing the realizations with the prescribed statistical properties is sampled uniformly.
4. The algorithm can easily be used for 2 and 3 dimensional realizations.
Besides these important advantages there are a few disadvantages of simulated
annealing.
1. As an optimization method it does not allow deviations from the prescribed
statistical properties. If these are estimated then their possible error hast to
be incorporated.
2. The algorithm is slow. The numerical realization of the simulation requires
fast computing possibilities and an effective formulation of the energy function changes.

109

9.6

Indicator Simulation

There are two main methods for simulating indicator variables. In one case a
continuous variable is simulated and the truncated into discrete classes according
to prescribed limits. In the other case indicators are simulated directly.

9.6.1

Truncated-Gaussian Simulation

The idea of the truncated gaussian approach is to simulate indicator values with
the help of a gaussian variable. Suppose Y (x) is a multigaussian random variable
with 0 mean and unit variance. In this case:
Ci = {x

;

si‚àí1 < Y (x) ‚â§ si }

(9.24)

defines a random set in the space. The probability of an x belonging to Ci can be
calculated as:
P(x ‚àà Ci ) = P(si‚àí1 < Y (x) ‚â§ si ) = Œ¶(si ) ‚àí Œ¶(si‚àí1 )

(9.25)

The thresholds si have to satisfy:
s0 = ‚àí‚àû

sn = +‚àû

The indicator variograms and cross-variograms can be calculated form the covariance matrix of the multigaussian variable Y (x)
Conditional simulation of the indicators ICi requires a further step as the corresponding Y values are unknown.

9.7

Application of simulations

There are several possible applications for unconditional and conditional simulations. The classical mining applications were forecasting quality fluctuations for
blending and processing.
110

It can also be successfully used in calibrating non linear complex systems
(like groundwater movement). In this case as the output of the system is not
linearly dependent on the regionalized variable usage of the kriged values does
not necessarily lead to expectations of the output. Thus using a set of simulations
can yield better estimates.
Another application is sensitivity analysis. Conditional simulations can help
to calculate realistic sensitivities, as both the dependence and the measurement
locations are considered.

9.7.1 Examples
Consider the problem of estimating areal rainfall for hydrological modelling and
extreme value statistics. Areal rainfall cannot be measured directly, and thus has
to be estimated on the basis of point values. The estimation can be done using OK
or EDK or IRF-k. In general this is done by interpolating precipitation values on a
dense regular grid, and then calculating the mean of the grid values corresponding
to the selected area (subcatchment). It is obvious that the probability of measuring
the maximum precipitation amounts at the raingauges is very low.

111

Chapter 10
Exercises
10.1

The Variogram

10.1.1

Question: 1

1. The matrix in figure 10.1 is considered to be a set of measurements (ex.
relative soil humidity in percent) on a regular grid with vertical (y) and horizontal (x) distance of 1 between neighbouring points.
Calculate the experimental variogram for horizontal (x,‚âà 0‚ó¶ ), vertical (y,‚âà
90‚ó¶ ) and for the diagonal (45‚ó¶ ) direction for the shortest possible nonzero
distance each.

10.1.2

Solution: 1

The general formula for the variogram - for a specific distance or vector h is:

Œ≥(h) =

1
‚àë (Z(ui) ‚àí Z(u j ))2
2N(h) ui ‚àíu
j =h

112

y
6

40

42

43

41

42

45

43

44

47
- x

Figure 10.1: A set of measurements
where N(h) is the number of pairs separated by the vector (or distance) h.
Applying the formula for this exercise gives:
1. for horizontal direction, minimal nonzero distance is 1, 6 pairs of the 3x3
matrix:

Œ≥(1hor ) =

1
((40 ‚àí 42)2 + (42 ‚àí 43)2 + (41 ‚àí 42)2 + (42 ‚àí 45)2 + (43 ‚àí 44)2 + (44 ‚àí 47)2 )
2¬∑6

Œ≥(1hor ) =

1
(22 + 12 + 12 + 32 + 12 + 32 )
2¬∑6

Œ≥(1hor ) =

25
= 2.083
12

2. for vertical direction, minimal nonzero distance is 1, 6 pairs of the 3x3
matrix:

113

Œ≥(1ver ) =

1
((40 ‚àí 41)2 + (41 ‚àí 43)2 + (42 ‚àí 42)2 + (42 ‚àí 44)2 + (43 ‚àí 45)2 + (45 ‚àí 47)2 )
2¬∑6

Œ≥(1ver ) =

1
(12 + 22 + 02 + 22 + 22 + 22 )
2¬∑6

Œ≥(1ver ) =

17
= 1.416
12

3. for diagonal (45‚ó¶ ) direction, minimal nonzero distance is 1.414 =

‚àö

2, 4

pairs of the 3x3 matrix:
Œ≥(1.41445 ) =

1
((41 ‚àí 42)2 + (43 ‚àí 42)2 + (42 ‚àí 43)2 + (44 ‚àí 45)2 )
2¬∑4

Œ≥(1.41445 ) =

1
(12 + 12 + 12 + 12 )
2¬∑4

Œ≥(1.41445 ) =

10.1.3

4
= 0.5
8

Question: 2

The following matrix is considered to be a set of measurements (ex. relative soil
humidity) on a regular grid with vertical (y) and horizontal (x) distance of 1 between neighbouring points:
Calculate the experimental indicator variograms for horizontal (x,‚âà 0‚ó¶ ), vertical (y,‚âà 90‚ó¶ ) direction for distance 1 each, using the indicator thresholds 0.3 and
0.4.
114

y
6

0.23

0.29

0.35

0.34

0.29

0.36

0.46

0.44

0.47
- x

10.1.4

Solution: 2

The general formula for the variogram - for a specific distance or vector h is:
Œ≥‚àó (h) =

1
‚àë (Z(ui) ‚àí Z(u j ))2
2N(h) ui ‚àíu
j =h

where N(h) is the number of pairs separated by the vector (or distance) h. The application of an indicator variable means to transform the matrix of measurements
to 0 and 1 values (0, if above threshold; 1, if below or equal). Applying this for
the threshold 0.3 gives:

y
6

1

1

0

0

1

0

0

0

0
- x

115

Applying the formula of the variogram on this gives:
Horizontal:
Œ≥‚àó (1hor ) =

1
((1 ‚àí 1)2 + (1 ‚àí 0)2 + (0 ‚àí 1)2 + (1 ‚àí 0)2 + (0 ‚àí 0)2 + (0 ‚àí 0)2 )
2¬∑6
Œ≥‚àó (1hor ) =

1
3
(0 + 1 + 1 + 1 + 0 + 0) =
= 0.25
12
12

Vertical:
Œ≥‚àó (1ver ) =

1
2
(1 + 0 + 0 + 1 + 0 + 0) =
= 0.1667
12
12

Applying this for the threshold 0.4 gives:

y
6

1

1

1

1

1

1

0

0

0
- x

Horizontal:
Œ≥‚àó (1hor ) =

1
0
(0 + 0 + 0 + 0 + 0 + 0) =
= 0.0
12
12

Œ≥‚àó (1ver ) =

1
3
(0 + 1 + 0 + 1 + 0 + 1) =
= 0.25
12
12

Vertical:

116

10.1.5

Question: 3

The following figure 10.2 presents a set of measurements of a parameter (ex. nitrate in mg/kg in the soil of a small field) on a regular grid of 1 m cell size. Fields
marked with ‚Äùx‚Äù are points without measurements:

y
6

5

19

21

24

26

4

x

18

x

x

3

11

x

15

x

2

x

13

x

22

1

11

x

15

18
- x

0

1

2

3

4

Figure 10.2: A set of measurements
Calculate the experimental variogram distances 1m and 2m in x and y direction.

117

10.1.6

Solution: 3

The general formula for the variogram - for a specific distance or vector h is:
Œ≥(h) =

1
‚àë (Z(ui) ‚àí Z(u j ))2
2N(h) ui ‚àíu
j =h

where N(h) is the number of pairs separated by the vector (or distance) h. Applying the formula gives:
1. for the horizontal direction (x) and distance 1m, 4 pairs of the matrix:
Œ≥(1hor ) =

1
((19 ‚àí 21)2 + (21 ‚àí 24)2 + (24 ‚àí 26)2 + (15 ‚àí 18)2 )
2¬∑4

Œ≥(1hor ) =

1
(22 + 32 + 22 + 32 )
2¬∑4

Œ≥(1hor ) =

26
= 3.25
8

2. for the vertical direction (y), distance 1m, 2 pairs of the matrix:

Œ≥(1ver ) =

1
((21 ‚àí 18)2 + (22 ‚àí 18)2 )
2¬∑2

Œ≥(1ver ) =

1
(32 + 42 )
2¬∑2

Œ≥(1ver ) =

25
= 6.25
4

118

3. for the horizontal direction (x) and distance 2 m, 5 pairs of the matrix:
Œ≥(2hor ) =

1
((19 ‚àí 24)2 + (21 ‚àí 26)2 + (11 ‚àí 15)2 + (13 ‚àí 22)2 + (11 ‚àí 15)2 )
2¬∑5

Œ≥(2hor ) =

1
(52 + 52 + 42 + 92 + 42 )
2¬∑5

Œ≥(2hor ) =

163
= 16.3
10

4. for vertical direction (y), distance 2m, 5 pairs of the matrix:

Œ≥(2ver ) =

1
((19 ‚àí 11)2 + (11 ‚àí 11)2 + (18 ‚àí 13)2 + (24 ‚àí 15)2 + (15 ‚àí 15)2 )
2¬∑5

Œ≥(1ver ) =

1
(82 + 02 + 52 + 92 + 02 )
2¬∑5

Œ≥(2ver ) =

10.1.7

170
= 17.0
10

Question: 4

Measurement of a certain physical quantity which varies spatially was carried
out at different locations. The measured values of the quantity and their spatial
locations are shown in figure 10.3.
Calculate the lag 1 indicator variogram for the quantity for a cut-off value of
31
1. in the x direction
2. in the y direction
3. without considering the direction.
119

30
q

25
q
y
6

35
q

32
q

27
q

-x

6

1
36
q

?


1

-

Figure 10.3: Spatial locations of measured values of the quantity

10.1.8

Solution: 4
IŒ± (u) = 1 if z(u) ‚â§ 31
IŒ± (u) = 0 if z(u) > 31
Œ≥‚àó (h) =

1
(IŒ± (ui ) ‚àí IŒ± (u j ))2
‚àë
2N(h) ui ‚àíu j =h

120

1. The variogram h = 1 and h = 2 in the x direction:
Œ≥‚àóx (1) =

1
1
(0 + 0 + 12 ) =
2¬∑3
6

1
1
Œ≥‚àóx (2) = (12 ) =
2
2
2. in the y direction
Œ≥‚àó (1) =

1
1
(12 + 12 + 0) =
2¬∑3
3

1
1
Œ≥‚àóy (2) = (1) =
2
2
3. without taking the direction into account:
Œ≥‚àó (1) =

1
1
(0 + 0 + 12 + 12 + 0 + 12 ) =
2¬∑6
4
Œ≥‚àó (2) =

1
1
(12 + 12 ) =
2¬∑2
2

10.2

Ordinary Kriging

10.2.1

Question: 1

The sketch in figure 10.4 shows 4 measurements Z(u) for points u = ‚àí2, ‚àí1, 1
and 2, ordered in a straight line. Write down the equations of an ordinary kriging
system for an estimation Z ‚àó at the point u = 0. For the variogram take the function
Œ≥(h) = h for a distance h. (Hint: it is not necessary to solve the equations!)

121

Z = 4.0
‚àí2

Z = 3.0

Z = 1.5

‚àí1

0

Z = 0.5

1

2

Figure 10.4: A sketch showing 4 measurements Z(u) for points u = ‚àí2, ‚àí1, 1,
and 2 ordered in a straight line.

10.2.2

Solution: 1

The kriging - system for ordinary kriging is
n

‚àë Œª j ¬∑ Œ≥(ui ‚àí u j ) + ¬µ = Œ≥(ui ‚àí u),

i = 1, . . . , n

j=1

n

‚àë Œªj = 1

j=1

with kriging weights Œªi for the measurement at ui , i = 1, ..., n. In this case,
with u1 = ‚àí2, u2 = ‚àí1, u3 = 1, u4 = 2 and the estimation of u = 0, the symmetry
of the locations leads to the symmetry of the weights so that:
Œª1 = Œª4 , Œª2 = Œª3
Therefore the equation system is reduced to 3 equations (i = 1, 2), because the
equations for i = 1, 4 and i = 2, 3 are identical:

i = 1: Œª1 ¬∑ Œ≥(0) + Œª2 ¬∑ Œ≥(1) + Œª2 ¬∑ Œ≥(3) + Œª1 ¬∑ Œ≥(4) + ¬µ = Œ≥(2)
i = 2: Œª1 ¬∑ Œ≥(1) + Œª2 ¬∑ Œ≥(0) + Œª2 ¬∑ Œ≥(2) + Œª1 ¬∑ Œ≥(3) + ¬µ = Œ≥(1)
2 ¬∑ Œª1 + 2 ¬∑ Œª2 = 1
122

-u

And by using the variogram function:

i =1: Œª1 ¬∑ 0 + Œª2 ¬∑ 1 + Œª2 ¬∑ 3 + Œª1 ¬∑ 4 + ¬µ = 2
i = 2: Œª1 ¬∑ 1 + Œª2 ¬∑ 0 + Œª2 ¬∑ 2 + Œª1 ¬∑ 3 + ¬µ = 1
2 ¬∑ Œª1 + 2 ¬∑ Œª2 = 1

i = 1: Œª1 ¬∑ 4 + Œª2 ¬∑ 4 + ¬µ = 2
i = 2: Œª1 ¬∑ 4 + Œª2 ¬∑ 2 + ¬µ = 1
2 ¬∑ Œª1 + 2 ¬∑ Œª2 = 1
The kriging system without using the symmetry is:

i = 1: Œª1 ¬∑ 0 + Œª2 ¬∑ 1 + Œª3 ¬∑ 3 + Œª4 ¬∑ 4 + ¬µ = 2
i = 2: Œª1 ¬∑ 1 + Œª2 ¬∑ 0 + Œª3 ¬∑ 2 + Œª4 ¬∑ 3 + ¬µ = 1
i = 3: Œª1 ¬∑ 3 + Œª2 ¬∑ 2 + Œª3 ¬∑ 0 + Œª4 ¬∑ 1 + ¬µ = 1
i = 4: Œª1 ¬∑ 4 + Œª2 ¬∑ 3 + Œª3 ¬∑ 1 + Œª4 ¬∑ 0 + ¬µ = 2
Œª1 + Œª2 + Œª3 + Œª4 = 1

123

The last equation leads to Œª2 = 0.5 ‚àí Œª1 , adding this to the previous equations
leads to:

i = 1: Œª1 ¬∑ 4 + (0.5 ‚àí Œª1 ) ¬∑ 4 + ¬µ = 2 + ¬µ = 2
i = 2: Œª1 ¬∑ 4 + (0.5 ‚àí Œª1 ) ¬∑ 2 + ¬µ = Œª1 ¬∑ 2 + 1 + ¬µ = 1
¬µ = 0 , Œª1 = 0 , Œª2 = 0.5
The kriging weights are 0.5 for u2 and u3 and 0 for u1 and u4 . The estimation
therefore is Z(u)=2.25.

10.2.3

Question: 2

The figure 10.5 presents a set of measurements of a parameter (ex. nitrate in
mg/kg in the soil of a small field) on a regular grid of 1m cell size. Fields marked
with ‚Äùx‚Äù are points without measurements:
Use the data given in the figure for the following calculations:
1. Write down the equations of an ordinary kriging system for the point (2,3)
using only the directly neighbouring points. For the variogram function take
Œ≥(h) = 4h. (Hint: it is not necessary to solve the equations!)
2. When using simple kriging instead of ordinary kriging, what kind of additional information do you need?

10.2.4

Solution: 2

1. The kriging - system for ordinary kriging is
n

‚àë Œª j ¬∑ Œ≥(ui ‚àí u j ) + ¬µ = Œ≥(ui ‚àí u),

j=1

124

i = 1, . . . , n

y
6

5

19

21

24

26

4

x

18

x

x

3

11

x

15

x

2

x

13

x

22

1

11

x

15

18
- x

0

1

2

3

4

Figure 10.5: A set of measurements
n

‚àë Œªj = 1

j=1

with kriging weights Œªi for the measurement at ui , i = 1, .., n. In this case the
neighbouring points of (2, 3) = u are: (1, 3) = u1 ,(2, 2) = u2 , (2, 4) = u3 ,
(3, 3) = u4
The distances in this configuration are:
1m (x and y direction) with Œ≥(1) = 4,
2m (x and y direction) with Œ≥(2) = 8,
1.41m (diagonal, ex. (2,2) to (3,3)) with Œ≥(1.41) = 5.64
The kriging system without using the symmetry is:
125

i = 1: Œª1 ¬∑ 0 + Œª2 ¬∑ Œ≥(1.41) + Œª3 ¬∑ Œ≥(1.41) + Œª4 ¬∑ Œ≥(2) + ¬µ = Œ≥(1)
i = 2: Œª1 ¬∑ Œ≥(1.41) + Œª2 ¬∑ 0 + Œª3 ¬∑ Œ≥(2) + Œª4 ¬∑ Œ≥(1.41) + ¬µ = Œ≥(1)
i = 3: Œª1 ¬∑ Œ≥(1.41) + Œª2 ¬∑ Œ≥(2) + Œª3 ¬∑ 0 + Œª4 ¬∑ Œ≥(1.41) + ¬µ = Œ≥(1)
i = 4: Œª1 ¬∑ Œ≥(2) + Œª2 ¬∑ Œ≥(1.41) + Œª3 ¬∑ Œ≥(1.41) + Œª4 ¬∑ 0 + ¬µ = Œ≥(1)
Œª1 + Œª2 + Œª3 + Œª4 = 1
and by evaluating the variogram Œ≥(h):

i = 1: Œª1 ¬∑ 0 + Œª2 ¬∑ 5.64 + Œª3 ¬∑ 5.64 + Œª4 ¬∑ 8 + ¬µ = 1 (1)
i = 2: Œª1 ¬∑ 5.64 + Œª2 ¬∑ 0 + Œª3 ¬∑ 8 + Œª4 ¬∑ 5.64 + ¬µ = 1 (2)
i = 3: Œª1 ¬∑ 5.64 + Œª2 ¬∑ 8 + Œª3 ¬∑ 0 + Œª4 ¬∑ 5.64 + ¬µ = 1 (3)
i = 4: Œª1 ¬∑ 8 + Œª2 ¬∑ 5.64 + Œª3 ¬∑ 5.64 + Œª4 ¬∑ 0 + ¬µ = 1 (4)
Œª1 + Œª2 + Œª3 + Œª4 = 1(5)
Calculating the differences between equation (2)-(3) and (1)-(4) leads to:
(2)-(3) : Œª2 = Œª3
(1)-(4): Œª1 = Œª4
evaluating these results in (1) and (2) and calculating the difference:
(1)-(2): Œª2 = Œª1
126

with (5) : Œª4 = Œª3 = Œª2 = Œª1 = 0.25
The kriging weights are 0.25 for all points. The estimation is therefore
Z(u) = 14.25.
The fast way to solution (but not to the kriging equations): By looking at the
symmetry of the points, it can be concluded that the system is invariant for
rotations of 90‚ó¶ . Because the variogram contains no anisotropy, the solution
must also be invariant for rotation. Therefore the solution is: equal weights
for all points!
2. For the application of simple kriging, the mean value of underlying process
m(u) at location u hast to be known. If m(u) is assumed as constant over the
domain, m(u) can be calculated as mean of the data.

10.2.5

Question: 3

The table 10.1 displays measurements of groundwater parameters Z(u) for
points u ordered in a straight line.
(a) Write down the equations of an external drift kriging system for an
estimation of Z ‚àó of chloride at the point u = 2 assuming that chloride
is linearly related to the electric conductivity. For the variogram take
the function Œ≥(h) = 32 h for a distance h. (hint: it is not necessary to
solve the equations!)
(b) What other methods can be used for the solution, if you consider the
dependency of chloride on electric conductivity? Please mention the
steps do you have to follow for these procedures?

127

Location (u)

Chloride[mg/l]

Electric Conductivity[mS/m]

0

19.4

20

1

22.2

22

2

‚Äì

21

3

23.6

24

4

24.8

25

Table 10.1: Measurements of groundwater parameters Z(u) for points u ordered
in a straight line

10.2.6

Solution: 3

(a) The equations of external drift kriging are as follows:
I

‚àë Œª j Œ≥(ui ‚àí u j ) + ¬µ1 + ¬µ2Y (ui) = Œ≥(ui ‚àí u)

i = 1, . . . , I

j=1

I

‚àë Œªj = 1

j=1

I

‚àë Œª jY (u j ) = Y (u)

j=1

Applying these formulas for this specific case leads to 6 equations, the
locations are: u1 =0, u2 =1, u3 =3, u4 =4 and u=2:

i = 1: Œª1 Œ≥(0) + Œª2 Œ≥(1) + Œª3 Œ≥(3) + Œª4 Œ≥(4) + ¬µ1 + ¬µ2Y (0) = Œ≥(2)
128

i = 2: Œª1 Œ≥(1) + Œª2 Œ≥(0) + Œª3 Œ≥(2) + Œª4 Œ≥(3) + ¬µ1 + ¬µ2Y (1) = Œ≥(1)
i = 3: Œª1 Œ≥(3) + Œª2 Œ≥(2) + Œª3 Œ≥(0) + Œª4 Œ≥(1) + ¬µ1 + ¬µ2Y (3) = Œ≥(1)
i = 4: Œª1 Œ≥(4) + Œª2 Œ≥(3) + Œª3 Œ≥(1) + Œª4 Œ≥(0) + ¬µ1 + ¬µ2Y (4) = Œ≥(2)
Œª1 + Œª2 + Œª3 + Œª4 = 1
Œª1Y (0) + Œª2Y (1) + Œª3Y (3) + Œª4Y (4) = Y (2)
Inserting the variogram Œ≥(h) = 32 h, and the values of the function Y
(electric conductivity) gives:

i = 1: 1.5 ¬∑ Œª2 + 4.5 ¬∑ Œª3 + 6 ¬∑ Œª4 + ¬µ1 + 20 ¬∑ ¬µ2 = 3
i = 2: 1.5 ¬∑ Œª1 + 3 ¬∑ Œª3 + 4.5 ¬∑ Œª4 + ¬µ1 + 22 ¬∑ ¬µ2 = 1.5
i = 3: 4.5 ¬∑ Œª1 + 3 ¬∑ Œª2 + 1.5 ¬∑ Œª4 + ¬µ1 + 24 ¬∑ ¬µ2 = 1.5
i = 4: 6 ¬∑ Œª1 + 4.5 ¬∑ Œª2 + 1.5 ¬∑ Œª3 + ¬µ1 + 25 ¬∑ ¬µ2 = 3
Œª1 + Œª2 + Œª3 + Œª4 = 1
20 ¬∑ Œª1 + 22 ¬∑ Œª2 + 24 ¬∑ Œª3 + 25 ¬∑ Œª4 = 21

129

(b) Other methods to use for this problem:
Cokriging:
When applying cokriging not only variograms of both parameters have
to be estimated, but also covariograms defining the relation between
both parameters. The advantage of cokriging is that it is not necessary
to have a measurement of the second parameter at the location of estimation.
Universal Kriging:
Universal kriging includes an explicit calculation of the external drift
(which is not necessarily a linear function!). Usually the variogram
has to be calculated iteratively using the residuals of the external drift
calculated before.
Instrinsic Random Functions of Order k:
For IRF-k a generalized covariance has to be calculated. Assuming a
linear trend IRF-1 (first order) is a suitable choice.

10.3

Short Questions

Please answer the following questions:

10.3.1

Question: 1

(a) Explain the role of the block-size on the estimation variance, when
utilising block kriging.
(b) Two different measurement methods are used for a certain parameter of groundwater quality making more than one measurement at
130

each point. Method A delivers locally constant values at all locations,
whereas Method B has an internal error producing local variances in
the measured data at each point. Local mean values of Method B are
the same of Method A. How do the variograms calculated for Method
A and Method B differ from each other?

10.3.2

Solution: 1

(a) The estimation variance of block kriging is given by the formula:
n

n

n

j=1 i=1

i=1

œÉ2 (V ) = ‚àíŒ≥(V,V ) ‚àí ‚àë ‚àë Œª j Œªi Œ≥(ui ‚àí u j ) + 2 ‚àë Œªi Œ≥(ui ,V )
The last term is the internal variance of the block. By increasing the
size of the block, the internal variance increases as well, and this decreases the estimation variance. Therefore the bigger the size of the
blocks, the smaller the estimation variance will be.
(b) The variogram of Method B is the one of Method A with an added
term cs corresponding to the internal error variance s (depending on
the formulas used for the estimation of variance and variogram, these
terms are not necessarily equal.) In case of Variogram A, there is no
nugget effect, the Variogram B will have a nugget effect of cs .

10.3.3

Question: 2

(a) Consider Simple Updating Kriging (SUK) and External Drift Kriging
(EDK) for interpolation. What kind of data do you need to apply these
methods?

(b) Based on the measured point-data, an interpolation and a simulation
are done to plot a map for each. What do you expect to observe, when
131

you consider the variograms calculated with these maps (interpolation
vs. simulation)? What kind of relations can you distinguish between
the variogram calculated and the variogram obtained from the original
dataset?

(c) When do you apply indicator kriging? Please define the cases where
indicator kriging can be applied and such where indicator kriging must
be applied!

10.3.4

Solution: 2

(a) Simple Updating Kriging (SUK) and External Drift Kriging (EDK)
both need additional information which has to be known at the points
of data and for the points of interpolation. For SUK, this information
has to be categorical (ex. discrete class-number), for EDK a linearly
related second variable is needed.

(b) The interpolation-variogram should have smaller values than the simulationvariogram. The simulation-variogram should be identical to the variogram of the original dataset.

(c) Categorical variables: Indicator Kriging (IK) must be applied.
Highly skewed distribution of parameter: Applying IK to different
thresholds can deliver more plausible results than the conventional
kriging methods.
Detection limit problems: If a high number of measurements is below
the detection limit, IK should be applied. If the percentage is significantly high (appr. 10% or higher) only IK can deliver plausible results.
Below 10%: A substitution of measurements below detection limit is

132

possible.
Below 5%: IK is not necessary.

133

Chapter 11
References
Journel, A. G. (1983): Non parametric estimation of spatial distributions.
Mathematical Geology, 15, 445-468.
Journel, A. G. and Zhu, H. (1990): Integrating Soft Seismic Data: MarkovBayes updating, an alternative to cokriging and traditional regression.
In Stanford Center for Reservoir Forecasting, Report 3, Stanford, 162.
Lehmann, W. (1995): Anwendung geostatistischer Verfahren auf die Bodenfeuchte in laÃàndlichen Einzugsgebieten. Mitteilungen des Instituts
fuÃàr Hydrologie und Wasserwirtschaft, Nr.52, UniversitaÃàt Karlsruhe.
Matheron, G. (1971): The Theory of Regionalized Variables and itsApplications. Les Cahiers du Centre de Morphologie MatheÃÅmatique, Fasc.
5.

134

